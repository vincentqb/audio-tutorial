{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other examples of dataset:\n",
    "* [torchvision](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py) and [here](https://github.com/pytorch/vision/blob/master/torchvision/datasets/utils.py)\n",
    "* generator for [tarballs](https://docs.python.org/3/library/tarfile.html#tarfile.TarFile.extractfile) and [zip](https://docs.python.org/3/library/zipfile.html#zipfile.ZipFile.open)\n",
    "* [AsrDataset](https://github.com/pytorch/fairseq/blob/4812f64b651ab64881510d38d4e35ce4ce22b04f/examples/speech_recognition/data/asr_dataset.py#L14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torchaudio\n",
    "\n",
    "import os\n",
    "import random\n",
    "from functools import reduce, partial\n",
    "from warnings import warn\n",
    "import pickle\n",
    "\n",
    "import six\n",
    "import csv\n",
    "import os\n",
    "import tarfile\n",
    "import logging\n",
    "import re\n",
    "import sys\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(URL):\n",
    "    r = requests.get(URL)\n",
    "    file_like_object = io.BytesIO(r.content)\n",
    "    tar = tarfile.open(fileobj=file_like_object)\n",
    "    d = {}\n",
    "    for member in tar.getmembers():\n",
    "        if member.isfile() and member.name.endswith('csv'):\n",
    "            k = 'train' if 'train' in member.name else 'test'\n",
    "            d[k] = tar.extractfile(member)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_csv_reader(unicode_csv_data, **kwargs):\n",
    "    r\"\"\"Since the standard csv library does not handle unicode in Python 2, we need a wrapper.\n",
    "    Borrowed and slightly modified from the Python docs:\n",
    "    https://docs.python.org/2/library/csv.html#csv-examples\n",
    "    Arguments:\n",
    "        unicode_csv_data: unicode csv data (see example below)\n",
    "    Examples:\n",
    "        >>> from torchtext.utils import unicode_csv_reader\n",
    "        >>> import io\n",
    "        >>> with io.open(data_path, encoding=\"utf8\") as f:\n",
    "        >>>     reader = unicode_csv_reader(f)\n",
    "    \"\"\"\n",
    "\n",
    "    # Fix field larger than field limit error\n",
    "    maxInt = sys.maxsize\n",
    "    while True:\n",
    "        # decrease the maxInt value by factor 10\n",
    "        # as long as the OverflowError occurs.\n",
    "        try:\n",
    "            csv.field_size_limit(maxInt)\n",
    "            break\n",
    "        except OverflowError:\n",
    "            maxInt = int(maxInt / 10)\n",
    "    csv.field_size_limit(maxInt)\n",
    "\n",
    "    if six.PY2:\n",
    "        # csv.py doesn't do Unicode; encode temporarily as UTF-8:\n",
    "        csv_reader = csv.reader(utf_8_encoder(unicode_csv_data), **kwargs)\n",
    "        for row in csv_reader:\n",
    "            # decode UTF-8 back to Unicode, cell by cell:\n",
    "            yield [cell.decode('utf-8') for cell in row]\n",
    "    else:\n",
    "        for line in csv.reader(unicode_csv_data, **kwargs):\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suggestions:\n",
    "* small functional\n",
    "* get length\n",
    "* shuffle\n",
    "* meaningful error on function mismatch\n",
    "* ~~cache or buffer~~\n",
    "* ~~generator~~\n",
    "* stream files from disk or web\n",
    "* stream archives\n",
    "* ~~no compose function~~\n",
    "* ~~currie instead of partial?~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    \"\"\"\n",
    "    Wrap a generator so that, whenever a new item is returned, it is saved to disk in a pickle.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, generator, location):\n",
    "        self.generator = generator\n",
    "        self.location = location\n",
    "\n",
    "        self._id = id(self)\n",
    "        self._cache = []\n",
    "        self._internal_index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._internal_index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._internal_index < len(self):\n",
    "            item = self[self._internal_index]\n",
    "        else:\n",
    "            item = next(self.generator)\n",
    "        \n",
    "            file = str(self._id) + \"-\" + str(len(self))\n",
    "            file = os.path.join(self.location, file)\n",
    "            self._cache.append(file)\n",
    "        \n",
    "            os.makedirs(self.location, exist_ok=True)\n",
    "            with open(file, 'wb') as file:\n",
    "                pickle.dump(item, file)\n",
    "\n",
    "        self._internal_index += 1\n",
    "        return item\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file = self._cache[index]\n",
    "        with open(file, 'rb') as file:\n",
    "            item = pickle.load(file)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return length of cache\n",
    "        return len(self._cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    \"\"\"\n",
    "    Wrap a generator so as to keep the last few in memory.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, generator, capacity=10):\n",
    "        self.generator = generator\n",
    "        self.capacity = capacity\n",
    "        self._cache = []\n",
    "        self._fill()\n",
    "    \n",
    "    def _fill(self):\n",
    "        while len(self._cache) <= self.capacity:\n",
    "            self._cache.append(next(self.generator))\n",
    "    \n",
    "    def __getitem__(self, n):\n",
    "        self._fill()\n",
    "        return self._cache[n]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        item = self._cache.pop(0)\n",
    "        self._fill()\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_to_file(urls, root_path):\n",
    "    \"\"\"\n",
    "    Download each url to root_path.\n",
    "    \n",
    "    Input: url generator, folder inside archive\n",
    "    Output: downloaded archive, folder inside archive\n",
    "    \"\"\"\n",
    "    for url, folder in urls:\n",
    "        # torchvision.datasets.utils.download_url(url, root_path)\n",
    "        file = os.path.join(root_path, os.path.basename(url))\n",
    "        yield file, folder\n",
    "    \n",
    "    \n",
    "def extract(files):\n",
    "    \"\"\"\n",
    "    Extract each archive to their respective folder.\n",
    "    \n",
    "    Input: (url, folder name inside archive) generator\n",
    "    Output: path to inside archive\n",
    "    \"\"\"\n",
    "    for file, folder in files:\n",
    "        # torchvision.datasets.utils.extract_archive(file)\n",
    "        path = os.path.dirname(file)\n",
    "        path = os.path.join(path, folder)\n",
    "        yield path\n",
    "          \n",
    "            \n",
    "def walk(paths, extension):\n",
    "    \"\"\"\n",
    "    Walk inside a path recursively to find all files with given extension.\n",
    "    \n",
    "    Input: path\n",
    "    Output: path, file name identifying a row of data\n",
    "    \"\"\"\n",
    "    for path in paths:\n",
    "        for dp, dn, fn in os.walk(path):\n",
    "            for f in fn:\n",
    "                if extension in f:\n",
    "                    yield path, f\n",
    "\n",
    "                    \n",
    "def shuffle(generator):\n",
    "    \"\"\"\n",
    "    Shuffle the order of a generator.\n",
    "    \n",
    "    Input: generator\n",
    "    Output: generator\n",
    "    \"\"\"\n",
    "\n",
    "    # Load whole generator in memory\n",
    "    generator = list(generator)\n",
    "    # print(len(generator))\n",
    "    random.shuffle(generator)\n",
    "    for g in generator:\n",
    "        yield g\n",
    "\n",
    "        \n",
    "def filtering(fileids, reference):\n",
    "    \"\"\"\n",
    "    Skip fileids that are not present in given reference file.\n",
    "    \n",
    "    Output: (path, file) generator, reference file\n",
    "    Output: path, file\n",
    "    \"\"\"\n",
    "    \n",
    "    path_old = \"\"\n",
    "    \n",
    "    for path, fileid in fileids:\n",
    "        \n",
    "        # Check if same path to avoid reloading the file constantly\n",
    "        if path != path_old:\n",
    "            ref = os.path.join(path, reference)\n",
    "            with open(ref) as ref:\n",
    "                r = \"\".join(ref.readlines())\n",
    "            path_old = path\n",
    "\n",
    "        # It would be more efficient to loop through the reference file instead\n",
    "        if fileid in r:\n",
    "            yield path, fileid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YesNo\n",
    "\n",
    "[original](https://www.openslr.org/1/), [torchaudio](https://pytorch.org/audio/_modules/torchaudio/datasets/yesno.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ['0', '1', '1', '1', '1', '1', '1', '1'],\n",
       " 'waveform': tensor([[3.0518e-05, 6.1035e-05, 3.0518e-05,  ..., 2.7466e-03, 1.8005e-03,\n",
       "          2.2888e-03]]),\n",
       " 'sample_rate': 8000}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_yesno(fileids):\n",
    "    \"\"\"\n",
    "    Load data corresponding to each YESNO fileids.\n",
    "    \n",
    "    Input: path, file name identifying a row of data\n",
    "    Output: label, waveform, sample_rate\n",
    "    \"\"\"\n",
    "    \n",
    "    extension = \".wav\"\n",
    "    for path, fileid in fileids:\n",
    "        file = os.path.join(path, fileid)\n",
    "        waveform, sample_rate = torchaudio.load(file)\n",
    "        label = os.path.basename(fileid).split(\".\")[0].split(\"_\")\n",
    "    \n",
    "        yield {\n",
    "            \"label\": label,\n",
    "            \"waveform\": waveform,\n",
    "            \"sample_rate\": sample_rate,\n",
    "        }\n",
    "        \n",
    "\n",
    "def YESNO(root):\n",
    "    \"\"\"\n",
    "    Cache a pipeline loading YESNO.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = [\n",
    "        (\"http://www.openslr.org/resources/1/waves_yesno.tar.gz\", \"waves_yesno\")\n",
    "    ]\n",
    "    \n",
    "    path = download(url, root_path=root)\n",
    "    path = extract(path)\n",
    "    path = walk(path, extension=\".wav\")\n",
    "    path = shuffle(path)\n",
    "    data = load_yesno(path)\n",
    "    \n",
    "    # return Buffer(data)\n",
    "    # return Cache(data, \"tmp/\")\n",
    "    return data\n",
    "\n",
    "\n",
    "data = YESNO(\"/Users/vincentqb/yesnotest\")\n",
    "\n",
    "next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ['1', '1', '1', '0', '1', '0', '1', '0'],\n",
       " 'waveform': tensor([[ 0.0016,  0.0017,  0.0016,  ..., -0.0016, -0.0010, -0.0002]]),\n",
       " 'sample_rate': 8000}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VCTK\n",
    "\n",
    "[original](https://datashare.is.ed.ac.uk/handle/10283/2651), [torchaudio](https://pytorch.org/audio/datasets.html?highlight=dataset#torchaudio.datasets.VCTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'p231_181',\n",
       " 'content': 'I am not ready to walk away.\\n',\n",
       " 'waveform': tensor([[-0.0117, -0.0173, -0.0150,  ...,  0.0106,  0.0099,  0.0113]]),\n",
       " 'sample_rate': 48000}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_vctk(fileids):\n",
    "    \"\"\"\n",
    "    Load data corresponding to each VCTK fileids.\n",
    "\n",
    "    Input: path, file name identifying a row of data\n",
    "    Output: id, content, waveform, sample_rate\n",
    "    \"\"\"\n",
    "    \n",
    "    txt_folder = \"txt\"\n",
    "    txt_extension = \".txt\"\n",
    "    \n",
    "    audio_folder = \"wav48\"\n",
    "    audio_extension = \".wav\"\n",
    "    \n",
    "    for path, fileid in fileids:\n",
    "        \n",
    "        fileid = os.path.basename(fileid).split(\".\")[0]\n",
    "        folder = fileid.split(\"_\")[0]\n",
    "        txt_file = os.path.join(path, txt_folder, folder, fileid + txt_extension)        \n",
    "        audio_file = os.path.join(path, audio_folder, folder, fileid + audio_extension)        \n",
    "        \n",
    "        try:\n",
    "            with open(txt_file) as txt_file:\n",
    "                content = txt_file.readlines()[0]\n",
    "        except FileNotFoundError:\n",
    "            warn(\"Translation not found for {}\".format(audio_file))\n",
    "            # warn(\"File not found: {}\".format(txt_file))\n",
    "            continue\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        \n",
    "        yield {\n",
    "            \"id\": fileid,\n",
    "            \"content\": content,\n",
    "            \"waveform\": waveform,\n",
    "            \"sample_rate\": sample_rate,\n",
    "        }\n",
    "        \n",
    "        \n",
    "def VCTK(root):\n",
    "    \"\"\"\n",
    "    Cache a pipeline loading VCTK.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = [\n",
    "        ('http://homepages.inf.ed.ac.uk/jyamagis/release/VCTK-Corpus.tar.gz', \"VCTK-Corpus/\")\n",
    "    ]\n",
    "    \n",
    "    path = download(url, root_path=root)\n",
    "    path = extract(path)\n",
    "    path = walk(path, extension=\".wav\")\n",
    "    path = shuffle(path)\n",
    "    data = load_vctk(path)\n",
    "    \n",
    "    # return Cache(data, \"tmp/\")\n",
    "    return data\n",
    "\n",
    "\n",
    "data = VCTK(\"/Users/vincentqb/vctktest/\")\n",
    "\n",
    "next(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LibriSpeech\n",
    "\n",
    "[original](http://www.openslr.org/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7850-73752-0015',\n",
       " 'content': 'WAS IT NOT ALL A DREAM OF HIS OWN CREATION WHILE HIS EYE HAD BEEN FIXED IN ABSTRACTION ON THAT BRIGHT AND FLOWING RIVER',\n",
       " 'waveform': tensor([[-0.0017, -0.0019, -0.0016,  ...,  0.0017,  0.0018,  0.0015]]),\n",
       " 'sample_rate': 16000}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_librispeech(fileids):\n",
    "    \"\"\"\n",
    "    Load data corresponding to each LIBRISPEECH fileids.\n",
    "    \n",
    "    Input: path, file name identifying a row of data\n",
    "    Output: id, waveform, sample_rate, translation\n",
    "    \"\"\"\n",
    "    \n",
    "    text_extension = \".trans.txt\"\n",
    "    audio_extension = \".flac\"\n",
    "    for data_path, fileid in fileids:\n",
    "        fileid = os.path.basename(fileid).split(\".\")[0]\n",
    "        folder1, folder2, file = fileid.split(\"-\")\n",
    "        file_text = folder1 + \"-\" + folder2 + text_extension\n",
    "        file_text = os.path.join(data_path, folder1, folder2, file_text)\n",
    "        file_audio = folder1 + \"-\"+ folder2 + \"-\" + file + audio_extension\n",
    "        file_audio = os.path.join(data_path, folder1, folder2, file_audio)\n",
    "        waveform, sample_rate = torchaudio.load(file_audio)\n",
    "        \n",
    "        found = False\n",
    "        for line in open(file_text):\n",
    "            fileid_text, content = line.strip().split(\" \", 1)\n",
    "            if fileid == fileid_text:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            from warnings import warn\n",
    "            warn(\"Translation not found for {}.\".format(fileid))\n",
    "            continue\n",
    "\n",
    "        yield {\n",
    "            \"id\": fileid,\n",
    "            \"content\": content,\n",
    "            \"waveform\": waveform,\n",
    "            \"sample_rate\": sample_rate,\n",
    "        }\n",
    "        \n",
    "\n",
    "def LIBRISPEECH(root, selection=\"dev-clean\"):\n",
    "    \"\"\"\n",
    "    Cache a pipeline loading LIBRISPEECH.\n",
    "    \"\"\"\n",
    "    \n",
    "    # http://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "    # http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "    # http://www.openslr.org/resources/12/test-other.tar.gz\n",
    "    # http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
    "    # http://www.openslr.org/resources/12/train-clean-360.tar.gz\n",
    "    # http://www.openslr.org/resources/12/train-other-500.tar.gz\n",
    "\n",
    "    selections = [\n",
    "        \"dev-clean\",\n",
    "        \"test-clean\",\n",
    "        \"test-other\",\n",
    "        \"train-clean-100\",\n",
    "        \"train-clean-360\",\n",
    "        \"train-other-500\"\n",
    "    ]\n",
    "        \n",
    "    base = \"http://www.openslr.org/resources/12/\"\n",
    "    url = [\n",
    "        (os.path.join(base, selection + \".tar.gz\"), os.path.join(\"LibriSpeech\", selection))\n",
    "    ]\n",
    "     \n",
    "    path = download(url, root_path=root)\n",
    "    path = extract(path)\n",
    "    path = walk(path, extension=\".flac\")\n",
    "    path = shuffle(path)\n",
    "    data = load_librispeech(path)\n",
    "    \n",
    "    # return Cache(data, \"tmp/\")\n",
    "    return data\n",
    "\n",
    "\n",
    "data = LIBRISPEECH(\"/Users/vincentqb/librispeechtest/\")\n",
    "\n",
    "next(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CommonVoice\n",
    "\n",
    "[original](https://voice.mozilla.org/en/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': '11d5e99f7bd5b4f8492a06bb1ec22aa9110bba6ea9918f2a9adec05d686304d568ab7063daf8915d3fccfb4dd44b81646bd13a33ca130ac4014560bba4c2db0b',\n",
       " 'path': 'common_voice_tt_17531596.mp3',\n",
       " 'sentence': 'Мин анда ялгыз бара алмам бит.',\n",
       " 'up_votes': '2',\n",
       " 'down_votes': '0',\n",
       " 'age': 'thirties',\n",
       " 'gender': 'male',\n",
       " 'accent': '',\n",
       " 'waveform': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.8685e-07,\n",
       "          -2.3097e-06, -2.8796e-06]]),\n",
       " 'sample_rate': 48000}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_commonvoice(fileids, tsv_file):\n",
    "    \"\"\"\n",
    "    Load data corresponding to each COMMONVOICE fileids.\n",
    "    \n",
    "    Input: path, file name identifying a row of data\n",
    "    Output: client_id, path, sentence, up_votes, down_votes, age, gender, accent, waveform, sample_rate\n",
    "    \"\"\"\n",
    "    \n",
    "    for path, fileid in fileids:\n",
    "        filename = os.path.join(path, \"clips\", fileid)\n",
    "        tsv = os.path.join(path, tsv_file)\n",
    "\n",
    "        found = False\n",
    "        with open(tsv) as tsv:\n",
    "            first_line = True\n",
    "            for line in unicode_csv_reader(tsv, delimiter='\\t'):\n",
    "                if first_line:\n",
    "                    header = line\n",
    "                    first_line = False\n",
    "                    continue\n",
    "                if fileid in line:\n",
    "                    found = True\n",
    "                    break\n",
    "        if not found:\n",
    "            continue\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(filename)    \n",
    "\n",
    "        dic = dict(zip(header, line))\n",
    "        dic[\"waveform\"] = waveform\n",
    "        dic[\"sample_rate\"] = sample_rate\n",
    "\n",
    "        yield dic\n",
    "\n",
    "\n",
    "def COMMONVOICE(root, language=\"tatar\", tsv=\"train.tsv\"):\n",
    "    \"\"\"\n",
    "    Cache a pipeline loading COMMONVOICE.\n",
    "    \"\"\"\n",
    "    \n",
    "    web = \"https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-3/\"\n",
    "\n",
    "    languages = {\n",
    "        \"tatar\": \"tt\",\n",
    "        \"english\": \"en\",\n",
    "        \"german\": \"de\",\n",
    "        \"french\": \"fr\",\n",
    "        \"welsh\": \"cy\",\n",
    "        \"breton\": \"br\",\n",
    "        \"chuvash\": \"cv\",\n",
    "        \"turkish\": \"tr\",\n",
    "        \"kyrgyz\": \"ky\",\n",
    "        \"irish\": \"ga-IE\",\n",
    "        \"kabyle\": \"kab\",\n",
    "        \"catalan\": \"ca\",\n",
    "        \"taiwanese\": \"zh-TW\",\n",
    "        \"slovenian\": \"sl\",\n",
    "        \"italian\": \"it\",\n",
    "        \"dutch\": \"nl\",\n",
    "        \"hakha chin\": \"cnh\",\n",
    "        \"esperanto\": \"eo\",\n",
    "        \"estonian\": \"et\",\n",
    "        \"persian\": \"fa\",\n",
    "        \"basque\": \"eu\",\n",
    "        \"spanish\": \"es\",\n",
    "        \"chinese\": \"zh-CN\",\n",
    "        \"mongolian\": \"mn\",\n",
    "        \"sakha\": \"sah\",\n",
    "        \"dhivehi\": \"dv\",\n",
    "        \"kinyarwanda\": \"rw\",\n",
    "        \"swedish\": \"sv-SE\",\n",
    "        \"russian\": \"ru\",\n",
    "    }\n",
    "\n",
    "    url = web + languages[language] + \".tar.gz\"\n",
    "    url = [(url, \"\")]\n",
    "     \n",
    "    path = download(url, root_path=root)\n",
    "    path = extract(path)\n",
    "    path = walk(path, extension=\".mp3\")\n",
    "    # path = shuffle(path)\n",
    "    # path = filtering(path, reference=tsv)\n",
    "    data = load_commonvoice(path, tsv)\n",
    "    \n",
    "    # return Cache(data, \"tmp/\")\n",
    "    return data\n",
    "\n",
    "\n",
    "data = COMMONVOICE(\"/Users/vincentqb/commonvoicetest/\")\n",
    "\n",
    "next(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
