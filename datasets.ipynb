{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other examples of dataset:\n",
    "* [torchvision](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py) and [here](https://github.com/pytorch/vision/blob/master/torchvision/datasets/utils.py)\n",
    "* generator for [tarballs](https://docs.python.org/3/library/tarfile.html#tarfile.TarFile.extractfile) and [zip](https://docs.python.org/3/library/zipfile.html#zipfile.ZipFile.open)\n",
    "* [AsrDataset](https://github.com/pytorch/fairseq/blob/4812f64b651ab64881510d38d4e35ce4ce22b04f/examples/speech_recognition/data/asr_dataset.py#L14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torchaudio\n",
    "\n",
    "import os\n",
    "import random\n",
    "from functools import reduce, partial\n",
    "from warnings import warn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(URL):\n",
    "    r = requests.get(URL)\n",
    "    file_like_object = io.BytesIO(r.content)\n",
    "    tar = tarfile.open(fileobj=file_like_object)\n",
    "    d = {}\n",
    "    for member in tar.getmembers():\n",
    "        if member.isfile() and member.name.endswith('csv'):\n",
    "            k = 'train' if 'train' in member.name else 'test'\n",
    "            d[k] = tar.extractfile(member)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suggestions:\n",
    "* small functional\n",
    "* get length\n",
    "* shuffle\n",
    "* meaningful error on function mismatch\n",
    "* ~~cache or buffer~~\n",
    "* ~~generator~~\n",
    "* stream files from disk or web\n",
    "* stream archives\n",
    "* ~~no compose function~~\n",
    "* ~~currie instead of partial?~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    \"\"\"\n",
    "    Wrap a generator so that, whenever a new item is returned, it is saved to disk in a pickle.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, generator, location):\n",
    "        self.generator = generator\n",
    "        self.location = location\n",
    "\n",
    "        self._id = id(self)\n",
    "        self._cache = []\n",
    "        self._internal_index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._internal_index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._internal_index < len(self):\n",
    "            item = self[self._internal_index]\n",
    "        else:\n",
    "            item = next(self.generator)\n",
    "        \n",
    "            file = str(self._id) + \"-\" + str(len(self))\n",
    "            file = os.path.join(self.location, file)\n",
    "            self._cache.append(file)\n",
    "        \n",
    "            os.makedirs(self.location, exist_ok=True)\n",
    "            with open(file, 'wb') as file:\n",
    "                pickle.dump(item, file)\n",
    "\n",
    "        self._internal_index += 1\n",
    "        return item\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file = self._cache[index]\n",
    "        with open(file, 'rb') as file:\n",
    "            item = pickle.load(file)\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return length of cache\n",
    "        return len(self._cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    \"\"\"\n",
    "    Wrap a generator so as to keep the last few in memory.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, generator, capacity=10):\n",
    "        self.generator = generator\n",
    "        self.capacity = capacity\n",
    "        self._cache = []\n",
    "        self._fill()\n",
    "    \n",
    "    def _fill(self):\n",
    "        while len(self._cache) <= self.capacity:\n",
    "            self._cache.append(next(self.generator))\n",
    "    \n",
    "    def __getitem__(self, n):\n",
    "        self._fill()\n",
    "        return self._cache[n]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        item = self._cache.pop(0)\n",
    "        self._fill()\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(urls, root_path):\n",
    "    \"\"\"\n",
    "    Download each url to root_path.\n",
    "    \n",
    "    Input: url generator, folder inside archive\n",
    "    Output: downloaded archive, folder inside archive\n",
    "    \"\"\"\n",
    "    for url, folder in urls:\n",
    "        # torchvision.datasets.utils.download_url(url, root_path)\n",
    "        file = os.path.join(root_path, os.path.basename(url))\n",
    "        yield file, folder\n",
    "    \n",
    "    \n",
    "def extract(files):\n",
    "    \"\"\"\n",
    "    Extract each archive to their respective folder.\n",
    "    \n",
    "    Input: (url, folder name inside archive) generator\n",
    "    Output: path to inside archive\n",
    "    \"\"\"\n",
    "    for file, folder in files:\n",
    "        # torchvision.datasets.utils.extract_archive(file)\n",
    "        path = os.path.dirname(file)\n",
    "        path = os.path.join(path, folder)\n",
    "        yield path\n",
    "          \n",
    "            \n",
    "def walk(paths, extension):\n",
    "    \"\"\"\n",
    "    Walk inside a path recursively to find all files with given extension.\n",
    "    \n",
    "    Input: path\n",
    "    Output: path, file name identifying a row of data\n",
    "    \"\"\"\n",
    "    for path in paths:\n",
    "        for dp, dn, fn in os.walk(path):\n",
    "            for f in fn:\n",
    "                if extension in f:\n",
    "                    yield path, f\n",
    "\n",
    "                    \n",
    "def shuffle(generator):\n",
    "    \"\"\"\n",
    "    Shuffle the order of a generator.\n",
    "    \n",
    "    Input: generator\n",
    "    Output: generator\n",
    "    \"\"\"\n",
    "\n",
    "    # Load whole generator in memory\n",
    "    generator = list(generator)\n",
    "    # print(len(generator))\n",
    "    random.shuffle(generator)\n",
    "    for g in generator:\n",
    "        yield g\n",
    "\n",
    "        \n",
    "def filtering(fileids, reference):\n",
    "    \"\"\"\n",
    "    Skip fileids that are not present in given reference file.\n",
    "    \n",
    "    Output: (path, file) generator, reference file\n",
    "    Output: path, file\n",
    "    \"\"\"\n",
    "    \n",
    "    path_old = \"\"\n",
    "    \n",
    "    for path, fileid in fileids:\n",
    "        \n",
    "        # Check if same path to avoid reloading the file constantly\n",
    "        if path != path_old:\n",
    "            ref = os.path.join(path, reference)\n",
    "            with open(ref) as ref:\n",
    "                r = \"\".join(ref.readlines())\n",
    "            path_old = path\n",
    "\n",
    "        # It would be more efficient to loop through the reference file instead\n",
    "        if fileid in r:\n",
    "            yield path, fileid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YesNo\n",
    "\n",
    "[original](https://www.openslr.org/1/), [torchaudio](https://pytorch.org/audio/_modules/torchaudio/datasets/yesno.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ['0', '1', '1', '1', '1', '1', '1', '1'],\n",
       " 'waveform': tensor([[3.0518e-05, 6.1035e-05, 3.0518e-05,  ..., 2.7466e-03, 1.8005e-03,\n",
       "          2.2888e-03]]),\n",
       " 'sample_rate': 8000}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_yesno(fileids):\n",
    "    \"\"\"\n",
    "    Load data corresponding to each YESNO fileids.\n",
    "    \n",
    "    Input: path, file name identifying a row of data\n",
    "    Output: label, waveform, sample_rate\n",
    "    \"\"\"\n",
    "    \n",
    "    extension = \".wav\"\n",
    "    for path, fileid in fileids:\n",
    "        file = os.path.join(path, fileid)\n",
    "        waveform, sample_rate = torchaudio.load(file)\n",
    "        label = os.path.basename(fileid).split(\".\")[0].split(\"_\")\n",
    "    \n",
    "        yield {\n",
    "            \"label\": label,\n",
    "            \"waveform\": waveform,\n",
    "            \"sample_rate\": sample_rate,\n",
    "        }\n",
    "        \n",
    "\n",
    "def YESNO(root):\n",
    "    \"\"\"\n",
    "    Cache a pipeline loading YESNO.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = [\n",
    "        (\"http://www.openslr.org/resources/1/waves_yesno.tar.gz\", \"waves_yesno\")\n",
    "    ]\n",
    "    \n",
    "    path = download(url, root_path=root)\n",
    "    path = extract(path)\n",
    "    path = walk(path, extension=\".wav\")\n",
    "    path = shuffle(path)\n",
    "    data = load_yesno(path)\n",
    "    \n",
    "    # return Buffer(data)\n",
    "    return Cache(data, \"tmp/\")\n",
    "\n",
    "\n",
    "data = YESNO(\"/Users/vincentqb/yesnotest\")\n",
    "\n",
    "next(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VCTK\n",
    "\n",
    "[original](https://datashare.is.ed.ac.uk/handle/10283/2651), [torchaudio](https://pytorch.org/audio/datasets.html?highlight=dataset#torchaudio.datasets.VCTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'p276_414',\n",
       " 'content': 'No plans for projects are yet in place.\\n',\n",
       " 'waveform': tensor([[-2.4719e-03, -2.7771e-03, -2.8381e-03,  ..., -6.1035e-04,\n",
       "          -3.0518e-05, -5.1880e-04]]),\n",
       " 'sample_rate': 48000}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_vctk(fileids):\n",
    "    \"\"\"\n",
    "    Load data corresponding to each VCTK fileids.\n",
    "\n",
    "    Input: path, file name identifying a row of data\n",
    "    Output: id, content, waveform, sample_rate\n",
    "    \"\"\"\n",
    "    \n",
    "    txt_folder = \"txt\"\n",
    "    txt_extension = \".txt\"\n",
    "    \n",
    "    audio_folder = \"wav48\"\n",
    "    audio_extension = \".wav\"\n",
    "    \n",
    "    for path, fileid in fileids:\n",
    "        \n",
    "        fileid = os.path.basename(fileid).split(\".\")[0]\n",
    "        folder = fileid.split(\"_\")[0]\n",
    "        txt_file = os.path.join(path, txt_folder, folder, fileid + txt_extension)        \n",
    "        audio_file = os.path.join(path, audio_folder, folder, fileid + audio_extension)        \n",
    "        \n",
    "        try:\n",
    "            with open(txt_file) as txt_file:\n",
    "                content = txt_file.readlines()[0]\n",
    "        except FileNotFoundError:\n",
    "            warn(\"Translation not found for {}\".format(audio_file))\n",
    "            # warn(\"File not found: {}\".format(txt_file))\n",
    "            continue\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "        \n",
    "        yield {\n",
    "            \"id\": fileid,\n",
    "            \"content\": content,\n",
    "            \"waveform\": waveform,\n",
    "            \"sample_rate\": sample_rate,\n",
    "        }\n",
    "        \n",
    "        \n",
    "def VCTK(root):\n",
    "    \"\"\"\n",
    "    Cache a pipeline loading VCTK.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = [\n",
    "        ('http://homepages.inf.ed.ac.uk/jyamagis/release/VCTK-Corpus.tar.gz', \"VCTK-Corpus/\")\n",
    "    ]\n",
    "    \n",
    "    path = download(url, root_path=root)\n",
    "    path = extract(path)\n",
    "    path = walk(path, extension=\".wav\")\n",
    "    path = shuffle(path)\n",
    "    data = load_vctk(path)\n",
    "    \n",
    "    return Cache(data, \"tmp/\")\n",
    "\n",
    "\n",
    "data = VCTK(\"/Users/vincentqb/vctktest/\")\n",
    "\n",
    "next(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LibriSpeech\n",
    "\n",
    "[original](http://www.openslr.org/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5895-34622-0012',\n",
       " 'content': 'THE CURIOSITY OF ONE PLACE EXHAUSTED THEY PASSED ON TO ANOTHER',\n",
       " 'waveform': tensor([[-0.0030, -0.0032, -0.0034,  ...,  0.0042,  0.0043,  0.0040]]),\n",
       " 'sample_rate': 16000}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_librispeech(fileids):\n",
    "    \"\"\"\n",
    "    Load data corresponding to each LIBRISPEECH fileids.\n",
    "    \n",
    "    Input: path, file name identifying a row of data\n",
    "    Output: id, waveform, sample_rate, translation\n",
    "    \"\"\"\n",
    "    \n",
    "    text_extension = \".trans.txt\"\n",
    "    audio_extension = \".flac\"\n",
    "    for data_path, fileid in fileids:\n",
    "        fileid = os.path.basename(fileid).split(\".\")[0]\n",
    "        folder1, folder2, file = fileid.split(\"-\")\n",
    "        file_text = folder1 + \"-\" + folder2 + text_extension\n",
    "        file_text = os.path.join(data_path, folder1, folder2, file_text)\n",
    "        file_audio = folder1 + \"-\"+ folder2 + \"-\" + file + audio_extension\n",
    "        file_audio = os.path.join(data_path, folder1, folder2, file_audio)\n",
    "        waveform, sample_rate = torchaudio.load(file_audio)\n",
    "        \n",
    "        found = False\n",
    "        for line in open(file_text):\n",
    "            fileid_text, content = line.strip().split(\" \", 1)\n",
    "            if fileid == fileid_text:\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            from warnings import warn\n",
    "            warn(\"Translation not found for {}.\".format(fileid))\n",
    "            continue\n",
    "\n",
    "        yield {\n",
    "            \"id\": fileid,\n",
    "            \"content\": content,\n",
    "            \"waveform\": waveform,\n",
    "            \"sample_rate\": sample_rate,\n",
    "        }\n",
    "        \n",
    "\n",
    "def LIBRISPEECH(root, selection=\"dev-clean\"):\n",
    "    \"\"\"\n",
    "    Cache a pipeline loading LIBRISPEECH.\n",
    "    \"\"\"\n",
    "    \n",
    "    # http://www.openslr.org/resources/12/dev-clean.tar.gz\n",
    "    # http://www.openslr.org/resources/12/test-clean.tar.gz\n",
    "    # http://www.openslr.org/resources/12/test-other.tar.gz\n",
    "    # http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
    "    # http://www.openslr.org/resources/12/train-clean-360.tar.gz\n",
    "    # http://www.openslr.org/resources/12/train-other-500.tar.gz\n",
    "\n",
    "    selections = [\n",
    "        \"dev-clean\",\n",
    "        \"test-clean\",\n",
    "        \"test-other\",\n",
    "        \"train-clean-100\",\n",
    "        \"train-clean-360\",\n",
    "        \"train-other-500\"\n",
    "    ]\n",
    "        \n",
    "    base = \"http://www.openslr.org/resources/12/\"\n",
    "    url = [\n",
    "        (os.path.join(base, selection + \".tar.gz\"), os.path.join(\"LibriSpeech\", selection))\n",
    "    ]\n",
    "     \n",
    "    path = download(url, root_path=root)\n",
    "    path = extract(path)\n",
    "    path = walk(path, extension=\".flac\")\n",
    "    path = shuffle(path)\n",
    "    data = load_librispeech(path)\n",
    "    \n",
    "    return Cache(data, \"tmp/\")\n",
    "\n",
    "\n",
    "data = LIBRISPEECH(\"/Users/vincentqb/librispeechtest/\")\n",
    "\n",
    "next(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CommonVoice\n",
    "\n",
    "[original](https://voice.mozilla.org/en/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': '11d5e99f7bd5b4f8492a06bb1ec22aa9110bba6ea9918f2a9adec05d686304d568ab7063daf8915d3fccfb4dd44b81646bd13a33ca130ac4014560bba4c2db0b',\n",
       " 'path': 'common_voice_tt_17523284.mp3',\n",
       " 'sentence': 'Ул күпернең өстендә җигүле бер тройка ат булсын.',\n",
       " 'up_votes': '2',\n",
       " 'down_votes': '0',\n",
       " 'age': 'thirties',\n",
       " 'gender': 'male',\n",
       " 'waveform': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -4.0065e-05,\n",
       "          -3.6392e-05, -3.1710e-05]]),\n",
       " 'sample_rate': 48000}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_commonvoice(fileids, tsv):\n",
    "    \"\"\"\n",
    "    Load data corresponding to each COMMONVOICE fileids.\n",
    "    \n",
    "    Input: path, file name identifying a row of data\n",
    "    Output: client_id, path, sentence, up_votes, down_votes, age, gender, accent, waveform, sample_rate\n",
    "    \"\"\"\n",
    "    \n",
    "    for path, fileid in fileids:\n",
    "        filename = os.path.join(path, \"clips\", fileid)\n",
    "        tsv = os.path.join(path, tsv)\n",
    "        \n",
    "        found = False\n",
    "        with open(tsv) as tsv:\n",
    "            header = next(tsv).strip().split(\"\\t\")\n",
    "            for line in tsv:\n",
    "                if fileid in line:\n",
    "                    # client_id, path, sentence, up_votes, down_votes, age, gender, accent\n",
    "                    line = line.strip().split(\"\\t\")\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                continue\n",
    "\n",
    "        waveform, sample_rate = torchaudio.load(filename)    \n",
    "\n",
    "        dic = dict(zip(header, line))\n",
    "        dic[\"waveform\"] = waveform\n",
    "        dic[\"sample_rate\"] = sample_rate\n",
    "\n",
    "        yield dic\n",
    "\n",
    "\n",
    "def COMMONVOICE(root, language=\"tatar\", tsv=\"train.tsv\"):\n",
    "    \"\"\"\n",
    "    Cache a pipeline loading COMMONVOICE.\n",
    "    \"\"\"\n",
    "    \n",
    "    web = \"https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-3/\"\n",
    "\n",
    "    languages = {\n",
    "        \"tatar\": \"tt\",\n",
    "        \"english\": \"en\",\n",
    "        \"german\": \"de\",\n",
    "        \"french\": \"fr\",\n",
    "        \"welsh\": \"cy\",\n",
    "        \"breton\": \"br\",\n",
    "        \"chuvash\": \"cv\",\n",
    "        \"turkish\": \"tr\",\n",
    "        \"kyrgyz\": \"ky\",\n",
    "        \"irish\": \"ga-IE\",\n",
    "        \"kabyle\": \"kab\",\n",
    "        \"catalan\": \"ca\",\n",
    "        \"taiwanese\": \"zh-TW\",\n",
    "        \"slovenian\": \"sl\",\n",
    "        \"italian\": \"it\",\n",
    "        \"dutch\": \"nl\",\n",
    "        \"hakha chin\": \"cnh\",\n",
    "        \"esperanto\": \"eo\",\n",
    "        \"estonian\": \"et\",\n",
    "        \"persian\": \"fa\",\n",
    "        \"basque\": \"eu\",\n",
    "        \"spanish\": \"es\",\n",
    "        \"chinese\": \"zh-CN\",\n",
    "        \"mongolian\": \"mn\",\n",
    "        \"sakha\": \"sah\",\n",
    "        \"dhivehi\": \"dv\",\n",
    "        \"kinyarwanda\": \"rw\",\n",
    "        \"swedish\": \"sv-SE\",\n",
    "        \"russian\": \"ru\",\n",
    "    }\n",
    "\n",
    "    url = web + languages[language] + \".tar.gz\"\n",
    "    url = [(url, \"\")]\n",
    "     \n",
    "    path = download(url, root_path=root)\n",
    "    path = extract(path)\n",
    "    path = walk(path, extension=\".mp3\")\n",
    "    path = shuffle(path)\n",
    "    path = filtering(path, reference=tsv)\n",
    "    data = load_commonvoice(path, tsv=tsv)\n",
    "    \n",
    "    return Cache(data, \"tmp/\")\n",
    "\n",
    "\n",
    "data = COMMONVOICE(\"/Users/vincentqb/commonvoicetest/\")\n",
    "\n",
    "next(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
