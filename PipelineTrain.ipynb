{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import cProfile\n",
    "import hashlib\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pstats\n",
    "import string\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn, topk\n",
    "from torch.optim import Adadelta, Adam, SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchaudio.datasets import SPEECHCOMMANDS, LIBRISPEECH\n",
    "from torchaudio.transforms import MFCC, Resample\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Empty CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Profiling performance\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GPUs\n",
      "200307.175930\n"
     ]
    }
   ],
   "source": [
    "audio_backend = \"soundfile\"\n",
    "torchaudio.set_audio_backend(audio_backend)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_devices = torch.cuda.device_count()\n",
    "print(num_devices, \"GPUs\")\n",
    "\n",
    "# max number of sentences per batch\n",
    "batch_size = 2048\n",
    "\n",
    "training_percentage = 100.\n",
    "validation_percentage = 0.\n",
    "\n",
    "data_loader_training_params = {\n",
    "    \"num_workers\": 0,\n",
    "    \"pin_memory\": False,\n",
    "    \"shuffle\": True,\n",
    "    \"drop_last\": True,\n",
    "}\n",
    "data_loader_validation_params = data_loader_training_params.copy()\n",
    "data_loader_validation_params[\"shuffle\"] = False\n",
    "\n",
    "non_blocking = data_loader_training_params[\"pin_memory\"]\n",
    "\n",
    "\n",
    "# text preprocessing\n",
    "\n",
    "char_null = \"-\"\n",
    "char_pad = \"*\"\n",
    "\n",
    "labels = [char_null + char_pad + string.ascii_lowercase]\n",
    "\n",
    "# excluded_dir = [\"_background_noise_\"]\n",
    "# folder_speechcommands = './SpeechCommands/speech_commands_v0.02'\n",
    "# labels = [char_null, char_pad] + [d for d in next(os.walk(folder_speechcommands))[1] if d not in excluded_dir]\n",
    "\n",
    "\n",
    "# audio\n",
    "\n",
    "sample_rate_original = 16000\n",
    "sample_rate_new = 1600\n",
    "# resample = Resample(sample_rate_original, sample_rate_new)\n",
    "\n",
    "n_mfcc = 13\n",
    "melkwargs = {\n",
    "    'n_fft': 512,\n",
    "    'n_mels': 20,\n",
    "    'hop_length': 80,  # (160, 80)\n",
    "}\n",
    "mfcc = MFCC(sample_rate=sample_rate_original, n_mfcc=n_mfcc, melkwargs=melkwargs).to(device)\n",
    "# mfcc = None\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "optimizer_params_adadelta = {\n",
    "    \"lr\": 1.0,\n",
    "    \"eps\": 1e-8,\n",
    "    \"rho\": 0.95,\n",
    "    # \"weight_decay\": .01,\n",
    "}\n",
    "\n",
    "optimizer_params_adam = {\n",
    "    \"lr\": .05,\n",
    "    \"eps\": 1e-8,\n",
    "    \"weight_decay\": .01,\n",
    "}\n",
    "\n",
    "optimizer_params_sgd = {\n",
    "    \"lr\": .001,\n",
    "    \"weight_decay\": .0001,\n",
    "}\n",
    "\n",
    "Optimizer = Adadelta\n",
    "optimizer_params = optimizer_params_adadelta\n",
    "\n",
    "gamma = 0.95\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "lstm_params = {\n",
    "    \"num_layers\": 3,\n",
    "    \"batch_first\": True,\n",
    "    \"bidirectional\": True,\n",
    "    # \"dropout\": 0.1,\n",
    "}\n",
    "\n",
    "clip_norm = 0.  # 10.\n",
    "\n",
    "zero_infinity = False\n",
    "\n",
    "max_epoch = 200\n",
    "mod_epoch = 10\n",
    "\n",
    "dtstamp = datetime.now().strftime(\"%y%m%d.%H%M%S\")\n",
    "print(dtstamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "class Coder:\n",
    "    def __init__(self, labels):\n",
    "        labels = list(collections.OrderedDict.fromkeys(list(\"\".join(labels))))\n",
    "        self.length = len(labels)\n",
    "        enumerated = list(enumerate(labels))\n",
    "        flipped = [(sub[1], sub[0]) for sub in enumerated]\n",
    "\n",
    "        d1 = collections.OrderedDict(enumerated)\n",
    "        d2 = collections.OrderedDict(flipped)\n",
    "        self.mapping = {**d1, **d2}\n",
    "\n",
    "    def _map(self, iterable):\n",
    "        # iterable to iterable\n",
    "        return [self.mapping[i] for i in iterable]\n",
    "\n",
    "    def encode(self, iterable):\n",
    "        if isinstance(iterable[0], list):\n",
    "            return [self.encode(i) for i in iterable]\n",
    "        else:\n",
    "            return self._map(iterable)\n",
    "\n",
    "    def decode(self, tensor):\n",
    "        if isinstance(tensor[0], list):\n",
    "            return [self.decode(t) for t in tensor]\n",
    "        else:\n",
    "            return \"\".join(self._map(tensor))\n",
    "\n",
    "\n",
    "coder = Coder(labels)\n",
    "encode = coder.encode\n",
    "decode = coder.decode\n",
    "vocab_size = coder.length\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class IterableMemoryCache:\n",
    "    def __init__(self, iterable):\n",
    "        self.iterable = iterable\n",
    "        self.iter = iter(iterable)\n",
    "        self.done = False\n",
    "        self.vals = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.done:\n",
    "            return iter(self.vals)\n",
    "        # chain vals so far & then gen the rest\n",
    "        return itertools.chain(self.vals, self._gen_iter())\n",
    "\n",
    "    def _gen_iter(self):\n",
    "        # gen new vals, appending as it goes\n",
    "        for new_val in self.iter:\n",
    "            self.vals.append(new_val)\n",
    "            yield new_val\n",
    "        self.done = True\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapMemoryCache(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Wrap a dataset so that, whenever a new item is returned, it is saved to memory.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self._id = id(self)\n",
    "        self._cache = [None] * len(dataset)\n",
    "\n",
    "    def __getitem__(self, n):\n",
    "        if self._cache[n]:\n",
    "            return self._cache[n]\n",
    "\n",
    "        item = self.dataset[n]\n",
    "        self._cache[n] = item\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# @torch.jit.script\n",
    "def process_datapoint(item):\n",
    "    transformed = item[0].to(device, non_blocking=non_blocking)\n",
    "    target = item[2].lower()\n",
    "    # target = \"\".join(filter(str.isalnum, target))\n",
    "    target = \"\".join(c for c in target if c.isalnum() or c == char_pad)\n",
    "    # pick first channel, apply mfcc, tranpose for pad_sequence\n",
    "    transformed = mfcc(transformed)\n",
    "    transformed = transformed[0, ...].transpose(0, -1)\n",
    "    # transformed = transformed.view(-1, 1)\n",
    "    target = encode(target)\n",
    "    target = torch.tensor(target, dtype=torch.long, device=transformed.device)\n",
    "    return transformed, target\n",
    "\n",
    "\n",
    "class PROCESSED_LIBRISPEECH(LIBRISPEECH):\n",
    "\n",
    "    def __getitem__(self, n):\n",
    "        try:\n",
    "            item = super().__getitem__(n)\n",
    "            return process_datapoint(item)\n",
    "        except (FileNotFoundError, RuntimeError):\n",
    "            return None\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            item = super().__next__()\n",
    "            return process_datapoint(item)\n",
    "        except (FileNotFoundError, RuntimeError):\n",
    "            return self.__next__()\n",
    "\n",
    "\n",
    "def datasets():\n",
    "    root = \"./\"\n",
    "\n",
    "    training = PROCESSED_LIBRISPEECH(root, url=\"train-clean-100\", download=True)\n",
    "    training = MapMemoryCache(training)\n",
    "    validation = PROCESSED_LIBRISPEECH(root, url=\"dev-clean\", download=True)\n",
    "    validation = MapMemoryCache(validation)\n",
    "\n",
    "    return training, validation, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_set(filename, validation_percentage, testing_percentage):\n",
    "    \"\"\"Determines which data partition the file should belong to.\n",
    "\n",
    "    We want to keep files in the same training, validation, or testing sets even\n",
    "    if new ones are added over time. This makes it less likely that testing\n",
    "    samples will accidentally be reused in training when long runs are restarted\n",
    "    for example. To keep this stability, a hash of the filename is taken and used\n",
    "    to determine which set it should belong to. This determination only depends on\n",
    "    the name and the set proportions, so it won't change as other files are added.\n",
    "\n",
    "    It's also useful to associate particular files as related (for example words\n",
    "    spoken by the same person), so anything after '_nohash_' in a filename is\n",
    "    ignored for set determination. This ensures that 'bobby_nohash_0.wav' and\n",
    "    'bobby_nohash_1.wav' are always in the same set, for example.\n",
    "\n",
    "    Args:\n",
    "        filename: File path of the data sample.\n",
    "        validation_percentage: How much of the data set to use for validation.\n",
    "        testing_percentage: How much of the data set to use for testing.\n",
    "\n",
    "    Returns:\n",
    "        String, one of 'training', 'validation', or 'testing'.\n",
    "    \"\"\"\n",
    "    \n",
    "    MAX_NUM_WAVS_PER_CLASS = 2**27 - 1  # ~134M\n",
    "\n",
    "    base_name = os.path.basename(filename)\n",
    "\n",
    "    # We want to ignore anything after '_nohash_' in the file name when\n",
    "    # deciding which set to put a wav in, so the data set creator has a way of\n",
    "    # grouping wavs that are close variations of each other.\n",
    "    hash_name = re.sub(r'_nohash_.*$', '', base_name).encode(\"utf-8\")\n",
    "    \n",
    "    # This looks a bit magical, but we need to decide whether this file should\n",
    "    # go into the training, testing, or validation sets, and we want to keep\n",
    "    # existing files in the same set even if more files are subsequently\n",
    "    # added.\n",
    "    # To do that, we need a stable way of deciding based on just the file name\n",
    "    # itself, so we do a hash of that and then use that to generate a\n",
    "    # probability value that we use to assign it.\n",
    "    hash_name_hashed = hashlib.sha1(hash_name).hexdigest()\n",
    "    percentage_hash = ((int(hash_name_hashed, 16) % (MAX_NUM_WAVS_PER_CLASS + 1)) * (100.0 / MAX_NUM_WAVS_PER_CLASS))\n",
    "    \n",
    "    if percentage_hash < validation_percentage:\n",
    "        result = 'validation'\n",
    "    elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "        result = 'testing'\n",
    "    else:\n",
    "        result = 'training'\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class FILTERED_SPEECHCOMMANDS(SPEECHCOMMANDS):\n",
    "    def __init__(self, tag, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if training_percentage < 100.:\n",
    "            testing_percentage = (100. - training_percentage - validation_percentage)\n",
    "            which_set = lambda x: which_set(x, validation_percentage, testing_percentage) == tag\n",
    "            self._walker = list(filter(which_set, self._walker))\n",
    "\n",
    "\n",
    "# @torch.jit.script\n",
    "def process_datapoint(item):\n",
    "    transformed = item[0].to(device, non_blocking=non_blocking)\n",
    "    target = item[2]\n",
    "    # pick first channel, apply mfcc, tranpose for pad_sequence\n",
    "    if mfcc is not None:\n",
    "        transformed = mfcc(transformed)\n",
    "    else:\n",
    "        transformed.unsqueeze(1)\n",
    "        transformed = resample(transformed)\n",
    "    transformed = transformed[0, ...].transpose(0, -1)\n",
    "    # transformed = transformed.view(-1, 1)\n",
    "    # print(target)\n",
    "    target = encode(target)\n",
    "    target = torch.tensor(target, dtype=torch.long, device=transformed.device)\n",
    "    # print(target)\n",
    "    return transformed, target\n",
    "\n",
    "\n",
    "class PROCESSED_SPEECHCOMMANDS(FILTERED_SPEECHCOMMANDS):\n",
    "\n",
    "    def __getitem__(self, n):\n",
    "        item = super().__getitem__(n)\n",
    "        return process_datapoint(item)\n",
    "\n",
    "    def __next__(self):\n",
    "        item = super().__next__()\n",
    "        return process_datapoint(item)\n",
    "\n",
    "\n",
    "def datasets():\n",
    "    root = \"./\"\n",
    "\n",
    "    training = PROCESSED_SPEECHCOMMANDS(\"training\", root, download=True)\n",
    "    training = MapMemoryCache(training)\n",
    "    validation = PROCESSED_SPEECHCOMMANDS(\"validation\", root, download=True)\n",
    "    validation = MapMemoryCache(validation)\n",
    "    testing = PROCESSED_SPEECHCOMMANDS(\"testing\", root, download=True)\n",
    "    testing = MapMemoryCache(testing)\n",
    "\n",
    "    return training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, _ = datasets()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "\n",
    "training_unprocessed = FILTERED_SPEECHCOMMANDS(\"training\", \"./\", download=True)\n",
    "\n",
    "counter = Counter([t[2] for t in training_unprocessed])\n",
    "\n",
    "plt.bar(counters.keys(), counter.values(), align='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "\n",
    "    tensors = [b[0] for b in batch if b]\n",
    "    tensors = torch.nn.utils.rnn.pad_sequence(tensors, batch_first=True)\n",
    "    tensors = tensors.transpose(1, -1)\n",
    "\n",
    "    targets = [b[1] for b in batch if b]\n",
    "    target_lengths = torch.tensor(\n",
    "        [target.shape[0] for target in targets], dtype=torch.long, device=tensors.device\n",
    "    )\n",
    "    targets = torch.nn.utils.rnn.pad_sequence(targets, batch_first=True)\n",
    "\n",
    "    # print(targets.shape)\n",
    "    # print(decode(targets.tolist()))\n",
    "    \n",
    "    return tensors, targets, target_lengths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "[Wav2Letter](https://github.com/LearnedVector/Wav2Letter/blob/master/Google%20Speech%20Command%20Example.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m): \n",
    "    if isinstance(m, nn.Linear):\n",
    "        size = m.weight.size()\n",
    "        fan_out = size[0] # number of rows\n",
    "        fan_in = size[1] # number of columns\n",
    "        variance = math.sqrt(2.0/(fan_in + fan_out))\n",
    "        m.weight.data.normal_(0.0, variance)\n",
    "\n",
    "\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Wav2Letter(nn.Module):\n",
    "    \"\"\"Wav2Letter Speech Recognition model\n",
    "        https://arxiv.org/pdf/1609.03193.pdf\n",
    "        This specific architecture accepts mfcc or power spectrums speech signals\n",
    "\n",
    "        Args:\n",
    "            num_features (int): number of mfcc features\n",
    "            num_classes (int): number of unique grapheme class labels\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv1d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv1d(num_features, 250, 48, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv1d(250, 250, 7),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv1d(250, 250, 7),\n",
    "            # nn.ReLU(),\n",
    "            nn.Conv1d(250, 2000, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(2000, 2000, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(2000, num_classes, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Forward pass through Wav2Letter network than\n",
    "            takes log probability of output\n",
    "        Args:\n",
    "            batch (int): mini batch of data\n",
    "            shape (batch, num_features, frame_len)\n",
    "        Returns:\n",
    "            Tensor with shape (batch_size, num_classes, output_len)\n",
    "        \"\"\"\n",
    "        # batch: (batch_size, num_features, seq_len)\n",
    "        y_pred = self.layers(batch)\n",
    "        # y_pred: (batch_size, num_classes, output_len)\n",
    "        y_pred = y_pred.transpose(-1, -2)\n",
    "        # y_pred: (batch_size, output_len, num_classes)\n",
    "        return nn.functional.log_softmax(y_pred, dim=-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, lstm_params):\n",
    "        super().__init__()\n",
    "        \n",
    "        bidirectional = lstm_params[\"bidirectional\"]\n",
    "        \n",
    "        if bidirectional:\n",
    "            directions = 2\n",
    "        else:\n",
    "            directions = 1\n",
    "\n",
    "        self.layer = nn.LSTM(num_features, hidden_size=num_classes, **lstm_params)\n",
    "        self.hidden2class = nn.Linear(directions*num_classes, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        self.layer.flatten_parameters()\n",
    "        # batch: batch, num_features, seq_len\n",
    "        batch = batch.transpose(-1, -2).contiguous()\n",
    "        # batch: batch, seq_len, num_features\n",
    "        outputs, _ = self.layer(batch)\n",
    "        # outputs: batch, seq_len, directions*num_features\n",
    "        outputs = self.hidden2class(outputs)\n",
    "        # outputs: batch, seq_len, num_features\n",
    "        return nn.functional.log_softmax(outputs, dim=-1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoder(outputs):\n",
    "    \"\"\"Greedy Decoder. Returns highest probability of class labels for each timestep\n",
    "\n",
    "    Args:\n",
    "        outputs (torch.Tensor): shape (input length, batch size, number of classes (including blank))\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: class labels per time step.\n",
    "    \"\"\"\n",
    "    _, indices = topk(outputs, k=1, dim=-1)\n",
    "    return indices[..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "loader_training = DataLoader(\n",
    "    training, batch_size=batch_size, collate_fn=collate_fn, **data_loader_training_params\n",
    ")\n",
    "\n",
    "loader_validation = DataLoader(\n",
    "    validation, batch_size=batch_size, collate_fn=collate_fn, **data_loader_validation_params\n",
    ")\n",
    "\n",
    "num_features = next(iter(loader_training))[0].shape[1]\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Wav2Letter(num_features, vocab_size)\n",
    "model = LSTMModel(num_features, vocab_size, lstm_params)\n",
    "\n",
    "# model = torch.jit.script(model)\n",
    "model = nn.DataParallel(model, [0,1]) if num_devices > 1 else model\n",
    "# model = nn.DataParallel(model) if num_devices > 1 else model\n",
    "model = model.to(device, non_blocking=non_blocking)\n",
    "# model.apply(weight_init)\n",
    "\n",
    "optimizer = Optimizer(model.parameters(), **optimizer_params)\n",
    "scheduler = ExponentialLR(optimizer, gamma=gamma)\n",
    "# scheduler = ReduceLROnPlateau(optimizer)\n",
    "\n",
    "criterion = torch.nn.CTCLoss(zero_infinity=zero_infinity)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = torch.nn.NLLLoss()\n",
    "\n",
    "best_loss = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_loss(inputs, targets, target_lengths):\n",
    "\n",
    "    inputs = inputs.to(device, non_blocking=non_blocking)\n",
    "    targets = targets.to(device, non_blocking=non_blocking)\n",
    "    \n",
    "    # keep batch first for data parallel\n",
    "    outputs = model(inputs).transpose(0, 1)\n",
    "\n",
    "    this_batch_size = outputs.shape[1]\n",
    "    seq_len = outputs.shape[0]\n",
    "    input_lengths = torch.full((this_batch_size,), seq_len, dtype=torch.long, device=outputs.device)\n",
    "    \n",
    "    # CTC    \n",
    "    # outputs: input length, batch size, number of classes (including blank)\n",
    "    # targets: batch size, max target length\n",
    "    # input_lengths: batch size\n",
    "    # target_lengths: batch size\n",
    "\n",
    "    return criterion(outputs, targets, input_lengths, target_lengths)\n",
    "\n",
    "\n",
    "def forward_and_decode(inputs, targets):\n",
    "    output = model(inputs)\n",
    "    output = output.transpose(0, 1)\n",
    "    output = output[:, 0, :]\n",
    "    output = greedy_decoder(output)\n",
    "    output = decode(output.tolist())\n",
    "    target = decode(targets.tolist()[0])\n",
    "\n",
    "    print_length = 20\n",
    "    output = output.ljust(print_length)[:print_length]\n",
    "    target = target.ljust(print_length)[:print_length]\n",
    "\n",
    "    return f\"Epoch: {epoch:4}   Target: {target}   Output: {output}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585c07b3c7204afcaa89ca1ece8654dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0   Target: happy---               Output: eeeeeeeeeeeeeeeeeeee\n",
      "Epoch:    0   Target: go                     Output: eeeeeeeeeeeeeeeeeeee\n",
      "Epoch:    0   Train: 175.70252   Validation: 158.02776\n",
      "Epoch:   10   Target: on------               Output: oooooooooooooooooooo\n",
      "Epoch:   10   Target: go                     Output: oooooooooooooooooooo\n",
      "Epoch:   10   Train: 76.26412   Validation: 75.28136\n",
      "Epoch:   20   Target: one-----               Output: oooooooooooooooooooo\n",
      "Epoch:   20   Target: go                     Output: oooooooooooooooooooo\n",
      "Epoch:   20   Train: 63.10353   Validation: 60.91565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   80   Target: off-----               Output: --------------------\n",
      "Epoch:   80   Target: go                     Output: --------------------\n",
      "Epoch:   80   Train: 3.21112   Validation: 3.20845\n",
      "Epoch:   90   Target: on------               Output: --------------------\n",
      "Epoch:   90   Target: go                     Output: --------------------\n",
      "Epoch:   90   Train: 3.18940   Validation: 3.18683\n",
      "Epoch:  100   Target: learn---               Output: --------------------\n",
      "Epoch:  100   Target: go                     Output: --------------------\n",
      "Epoch:  100   Train: 3.17200   Validation: 3.16972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  150   Target: down----               Output: --------------------\n",
      "Epoch:  150   Target: go                     Output: --------------------\n",
      "Epoch:  150   Train: 3.11721   Validation: 3.11560\n",
      "Epoch:  160   Target: seven---               Output: --------------------\n",
      "Epoch:  160   Target: go                     Output: --------------------\n",
      "Epoch:  160   Train: 3.10948   Validation: 3.10778\n",
      "Epoch:  170   Target: left----               Output: --------------------\n",
      "Epoch:  170   Target: go                     Output: --------------------\n",
      "Epoch:  170   Train: 3.10211   Validation: 3.10047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sum_loss_training = []\n",
    "sum_loss_validation = []\n",
    "\n",
    "with tqdm(total=max_epoch, unit_scale=1) as pbar:\n",
    "    for epoch in range(max_epoch):\n",
    "        model.train()\n",
    "\n",
    "        sum_loss = 0.\n",
    "        for inputs, targets, target_lengths in loader_training:\n",
    "\n",
    "            loss = forward_and_loss(inputs, targets, target_lengths)\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if clip_norm > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1/len(loader_training))\n",
    "\n",
    "        # Average loss\n",
    "        sum_loss = sum_loss / len(loader_training)\n",
    "        sum_loss_training.append((epoch, sum_loss))\n",
    "        sum_loss_str = f\"Epoch: {epoch:4}   Train: {sum_loss:4.5f}\"\n",
    "        \n",
    "        # scheduler.step()\n",
    "        # scheduler.step(sum_loss)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            if not epoch % mod_epoch:\n",
    "            \n",
    "                # Switch to evaluation mode\n",
    "                model.eval()\n",
    "        \n",
    "                print(forward_and_decode(inputs, targets))\n",
    "\n",
    "                sum_loss = 0.\n",
    "                for inputs, targets, target_lengths in loader_validation:\n",
    "\n",
    "                    sum_loss += forward_and_loss(inputs, targets, target_lengths).item()\n",
    "\n",
    "                # Average loss\n",
    "                sum_loss = sum_loss / len(loader_validation)\n",
    "                sum_loss_validation.append((epoch, sum_loss))\n",
    "                sum_loss_str += f\"   Validation: {sum_loss:.5f}\"\n",
    "\n",
    "                print(forward_and_decode(inputs, targets))\n",
    "\n",
    "                print(sum_loss_str)\n",
    "\n",
    "                if sum_loss < best_loss:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), f\"./model.{dtstamp}.{epoch}.ph\")\n",
    "                    best_loss = sum_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(*zip(*sum_loss_training), label=\"training\")\n",
    "plt.plot(*zip(*sum_loss_validation), label=\"validation\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_loss_training = [(a, math.log(b)) for (a,b) in sum_loss_training]\n",
    "sum_loss_validation = [(a, math.log(b)) for (a,b) in sum_loss_validation]\n",
    "\n",
    "plt.plot(*zip(*sum_loss_training), label=\"training\")\n",
    "plt.plot(*zip(*sum_loss_validation), label=\"validation\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         274001340 function calls (272388373 primitive calls) in 2261.539 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2437 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "     48/7    0.000    0.000 2261.536  323.077 gen.py:716(run)\n",
      "        7    0.000    0.000 2261.536  323.077 base_events.py:1686(_run_once)\n",
      "    75/22    0.000    0.000 2261.536  102.797 {method 'send' of 'generator' objects}\n",
      "      105    0.000    0.000 2261.536   21.538 events.py:86(_run)\n",
      "      105    0.000    0.000 2261.536   21.538 {method 'run' of 'Context' objects}\n",
      "       78    0.000    0.000 2261.536   28.994 ioloop.py:735(_run_callback)\n",
      "        5    0.000    0.000 2261.533  452.307 ioloop.py:690(<lambda>)\n",
      "        5    0.000    0.000 2261.533  452.307 gen.py:784(inner)\n",
      "    60/17    0.001    0.000 2261.532  133.031 gen.py:184(wrapper)\n",
      "       30    0.001    0.000 2261.531   75.384 kernelbase.py:225(dispatch_shell)\n",
      "       45    0.000    0.000 2261.531   50.256 kernelbase.py:347(process_one)\n",
      "331257/45    0.410    0.000 2261.516   50.256 {built-in method builtins.next}\n",
      "       30    0.001    0.000 2261.506   75.384 kernelbase.py:512(execute_request)\n",
      "    45/21    0.000    0.000 2261.504  107.691 gen.py:700(__init__)\n",
      "       15    0.000    0.000 2261.497  150.766 kernelbase.py:363(dispatch_queue)\n",
      "       15    0.000    0.000 2261.474  150.765 ipkernel.py:262(do_execute)\n",
      "       15    0.000    0.000 2261.436  150.762 zmqshell.py:534(run_cell)\n",
      "       15    0.000    0.000 2261.436  150.762 interactiveshell.py:2831(run_cell)\n",
      "       15    0.000    0.000 2261.435  150.762 interactiveshell.py:2865(_run_cell)\n",
      "       15    0.000    0.000 2261.400  150.760 async_helpers.py:58(_pseudo_sync_runner)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), f\"./model.{dtstamp}.{epoch}.ph\")\n",
    "\n",
    "# Print performance\n",
    "pr.disable()\n",
    "s = StringIO()\n",
    "ps = pstats.Stats(pr, stream=s).strip_dirs().sort_stats(\"cumtime\").print_stats(20)\n",
    "print(s.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
