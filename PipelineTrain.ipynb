{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import cProfile\n",
    "import hashlib\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pstats\n",
    "import string\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn, topk\n",
    "from torch.optim import Adadelta, Adam, SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchaudio.datasets import SPEECHCOMMANDS, LIBRISPEECH\n",
    "from torchaudio.transforms import MFCC, Resample\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Empty CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Profiling performance\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GPUs\n",
      "200315.162920\n"
     ]
    }
   ],
   "source": [
    "audio_backend = \"soundfile\"\n",
    "torchaudio.set_audio_backend(audio_backend)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_devices = torch.cuda.device_count()\n",
    "# num_devices = 1\n",
    "print(num_devices, \"GPUs\")\n",
    "\n",
    "# max number of sentences per batch\n",
    "# batch_size = 2048\n",
    "# batch_size = 512\n",
    "# batch_size = 256\n",
    "batch_size = 64\n",
    "\n",
    "training_percentage = 90.\n",
    "validation_percentage = 5.\n",
    "\n",
    "data_loader_training_params = {\n",
    "    \"num_workers\": 0,\n",
    "    \"pin_memory\": True,\n",
    "    \"shuffle\": True,\n",
    "    \"drop_last\": True,\n",
    "}\n",
    "data_loader_validation_params = data_loader_training_params.copy()\n",
    "data_loader_validation_params[\"shuffle\"] = False\n",
    "\n",
    "non_blocking = True\n",
    "\n",
    "\n",
    "# text preprocessing\n",
    "\n",
    "char_null = \"-\"\n",
    "char_space = \" \"\n",
    "char_pad = \"*\"\n",
    "char_apostrophe = \"'\"\n",
    "\n",
    "labels = [char_null + char_pad + char_apostrophe + string.ascii_lowercase]\n",
    "\n",
    "# excluded_dir = [\"_background_noise_\"]\n",
    "# folder_speechcommands = './SpeechCommands/speech_commands_v0.02'\n",
    "# labels = [char_null, char_pad] + [d for d in next(os.walk(folder_speechcommands))[1] if d not in excluded_dir]\n",
    "\n",
    "\n",
    "# audio\n",
    "\n",
    "sample_rate_original = 16000\n",
    "sample_rate_new = 8000\n",
    "# resample = Resample(sample_rate_original, sample_rate_new).to(device)\n",
    "resample = None\n",
    "\n",
    "n_mfcc = 13\n",
    "melkwargs = {\n",
    "    'n_fft': 512,\n",
    "    'n_mels': 20,\n",
    "    'hop_length': 80,  # (160, 80)\n",
    "}\n",
    "mfcc = MFCC(sample_rate=sample_rate_original, n_mfcc=n_mfcc, melkwargs=melkwargs).to(device)\n",
    "# mfcc = None\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "optimizer_params_adadelta = {\n",
    "    \"lr\": 1.0,\n",
    "    \"eps\": 1e-8,\n",
    "    \"rho\": 0.95,\n",
    "    \"weight_decay\": 1e-5,\n",
    "}\n",
    "\n",
    "optimizer_params_adam = {\n",
    "    \"lr\": .05,\n",
    "    \"eps\": 1e-8,\n",
    "    \"weight_decay\": .01,\n",
    "}\n",
    "\n",
    "optimizer_params_sgd = {\n",
    "    \"lr\": .001,\n",
    "    \"weight_decay\": .0001,\n",
    "}\n",
    "\n",
    "Optimizer = Adadelta\n",
    "optimizer_params = optimizer_params_adadelta\n",
    "\n",
    "gamma = 0.95\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "num_features = n_mfcc if n_mfcc else 1\n",
    "\n",
    "lstm_params = {\n",
    "    \"num_layers\": 3,\n",
    "    \"batch_first\": False,\n",
    "    \"bidirectional\": False,\n",
    "    \"dropout\": 0.,\n",
    "}\n",
    "\n",
    "clip_norm = 0.  # 10.\n",
    "\n",
    "zero_infinity = False\n",
    "\n",
    "max_epoch = 200\n",
    "mod_epoch = 10\n",
    "\n",
    "dtstamp = datetime.now().strftime(\"%y%m%d.%H%M%S\")\n",
    "print(dtstamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "class Coder:\n",
    "    def __init__(self, labels):\n",
    "        labels = list(collections.OrderedDict.fromkeys(list(\"\".join(labels))))\n",
    "        self.length = len(labels)\n",
    "        enumerated = list(enumerate(labels))\n",
    "        flipped = [(sub[1], sub[0]) for sub in enumerated]\n",
    "\n",
    "        d1 = collections.OrderedDict(enumerated)\n",
    "        d2 = collections.OrderedDict(flipped)\n",
    "        self.mapping = {**d1, **d2}\n",
    "        self.mapping[char_space] = self.mapping[char_pad]\n",
    "\n",
    "    def _map(self, iterable):\n",
    "        # iterable to iterable\n",
    "        return [self.mapping[i] for i in iterable]\n",
    "\n",
    "    def encode(self, iterable):\n",
    "        if isinstance(iterable[0], list):\n",
    "            return [self.encode(i) for i in iterable]\n",
    "        else:\n",
    "            return self._map(iterable)\n",
    "\n",
    "    def decode(self, tensor):\n",
    "        if isinstance(tensor[0], list):\n",
    "            return [self.decode(t) for t in tensor]\n",
    "        else:\n",
    "            # not idempotent, since clean string\n",
    "            return \"\".join(self._map(tensor)).replace(char_null, \"\").replace(char_pad, char_space).strip()\n",
    "\n",
    "\n",
    "coder = Coder(labels)\n",
    "encode = coder.encode\n",
    "decode = coder.decode\n",
    "vocab_size = coder.length\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterableMemoryCache:\n",
    "\n",
    "    def __init__(self, iterable):\n",
    "        self.iterable = iterable\n",
    "        self._iter = iter(iterable)\n",
    "        self._done = False\n",
    "        self._values = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self._done:\n",
    "            return iter(self._values)\n",
    "        return itertools.chain(self._values, self._gen_iter())\n",
    "\n",
    "    def _gen_iter(self):\n",
    "        for new_values in self._iter:\n",
    "            self._values.append(new_value)\n",
    "            yield new_value\n",
    "        self._done = True\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._iterable)\n",
    "\n",
    "\n",
    "class MapMemoryCache(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Wrap a dataset so that, whenever a new item is returned, it is saved to memory.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self._cache = [None] * len(dataset)\n",
    "\n",
    "    def __getitem__(self, n):\n",
    "        if self._cache[n]:\n",
    "            return self._cache[n]\n",
    "\n",
    "        item = self.dataset[n]\n",
    "        self._cache[n] = item\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "class Processed(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, process_datapoint, dataset):\n",
    "        self.process_datapoint = process_datapoint\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __getitem__(self, n):\n",
    "        try:\n",
    "            item = self.dataset[n]\n",
    "            return self.process_datapoint(item)\n",
    "        except (FileNotFoundError, RuntimeError):\n",
    "            return None\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            item = next(self.dataset)\n",
    "            return self.process_datapoint(item)\n",
    "        except (FileNotFoundError, RuntimeError):\n",
    "            return self.__next__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.jit.script\n",
    "def process_datapoint(item):\n",
    "    transformed = item[0].to(device, non_blocking=non_blocking)\n",
    "    target = item[2].lower().replace(char_space, char_pad)\n",
    "\n",
    "    # apply mfcc, tranpose for pad_sequence\n",
    "    if resample is not None:\n",
    "        transformed = resample(transformed)\n",
    "    \n",
    "    if mfcc is not None:\n",
    "        transformed = mfcc(transformed)\n",
    "    else:\n",
    "        transformed = transformed.unsqueeze(1)\n",
    "    \n",
    "    transformed = transformed[0, ...].transpose(0, -1)\n",
    "    \n",
    "    target = encode(target)\n",
    "    target = torch.tensor(target, dtype=torch.long, device=transformed.device)\n",
    "\n",
    "    transformed = transformed.to(\"cpu\")\n",
    "    target = target.to(\"cpu\")\n",
    "    return transformed, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets():\n",
    "\n",
    "    root = \"./\"\n",
    "    def create(tag):\n",
    "        data = LIBRISPEECH(root, tag, download=True)\n",
    "        data = Processed(process_datapoint, data)\n",
    "        data = MapMemoryCache(data)\n",
    "        return data\n",
    "\n",
    "    return create(\"train-clean-100\"), create(\"dev-clean\"), None\n",
    "\n",
    "\n",
    "training, validation, _ = datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_set(filename, validation_percentage, testing_percentage):\n",
    "    \"\"\"Determines which data partition the file should belong to.\n",
    "\n",
    "    We want to keep files in the same training, validation, or testing sets even\n",
    "    if new ones are added over time. This makes it less likely that testing\n",
    "    samples will accidentally be reused in training when long runs are restarted\n",
    "    for example. To keep this stability, a hash of the filename is taken and used\n",
    "    to determine which set it should belong to. This determination only depends on\n",
    "    the name and the set proportions, so it won't change as other files are added.\n",
    "\n",
    "    It's also useful to associate particular files as related (for example words\n",
    "    spoken by the same person), so anything after '_nohash_' in a filename is\n",
    "    ignored for set determination. This ensures that 'bobby_nohash_0.wav' and\n",
    "    'bobby_nohash_1.wav' are always in the same set, for example.\n",
    "\n",
    "    Args:\n",
    "        filename: File path of the data sample.\n",
    "        validation_percentage: How much of the data set to use for validation.\n",
    "        testing_percentage: How much of the data set to use for testing.\n",
    "\n",
    "    Returns:\n",
    "        String, one of 'training', 'validation', or 'testing'.\n",
    "    \"\"\"\n",
    "    \n",
    "    MAX_NUM_WAVS_PER_CLASS = 2**27 - 1  # ~134M\n",
    "\n",
    "    base_name = os.path.basename(filename)\n",
    "\n",
    "    # We want to ignore anything after '_nohash_' in the file name when\n",
    "    # deciding which set to put a wav in, so the data set creator has a way of\n",
    "    # grouping wavs that are close variations of each other.\n",
    "    hash_name = re.sub(r'_nohash_.*$', '', base_name).encode(\"utf-8\")\n",
    "    \n",
    "    # This looks a bit magical, but we need to decide whether this file should\n",
    "    # go into the training, testing, or validation sets, and we want to keep\n",
    "    # existing files in the same set even if more files are subsequently\n",
    "    # added.\n",
    "    # To do that, we need a stable way of deciding based on just the file name\n",
    "    # itself, so we do a hash of that and then use that to generate a\n",
    "    # probability value that we use to assign it.\n",
    "    hash_name_hashed = hashlib.sha1(hash_name).hexdigest()\n",
    "    percentage_hash = ((int(hash_name_hashed, 16) % (MAX_NUM_WAVS_PER_CLASS + 1)) * (100.0 / MAX_NUM_WAVS_PER_CLASS))\n",
    "    \n",
    "    if percentage_hash < validation_percentage:\n",
    "        result = 'validation'\n",
    "    elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "        result = 'testing'\n",
    "    else:\n",
    "        result = 'training'\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def filter_speechcommands(tag, training_percentage, data):\n",
    "    if training_percentage < 100.:\n",
    "            testing_percentage = (100. - training_percentage - validation_percentage)\n",
    "            which_set_filter = lambda x: which_set(x, validation_percentage, testing_percentage) == tag\n",
    "            data._walker = list(filter(which_set_filter, data._walker))\n",
    "    return data\n",
    "\n",
    "\n",
    "def datasets():\n",
    "\n",
    "    root = \"./\"\n",
    "    def create(tag):\n",
    "        data = SPEECHCOMMANDS(root, download=True)\n",
    "        data = filter_speechcommands(tag, training_percentage, data)\n",
    "        data = Processed(process_datapoint, data)\n",
    "        data = MapMemoryCache(data)\n",
    "        return data\n",
    "\n",
    "    return create(\"training\"), create(\"validation\"), create(\"testing\")\n",
    "\n",
    "\n",
    "# training, validation, _ = datasets()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "training_unprocessed = SPEECHCOMMANDS(\"./\", download=True)\n",
    "training_unprocessed = filter_speechcommands(training_percentage, training_unprocessed)\n",
    "\n",
    "counter = Counter([t[2] for t in training_unprocessed])\n",
    "counter = OrderedDict(counter.most_common())\n",
    "\n",
    "plt.bar(counter.keys(), counter.values(), align='center')\n",
    "\n",
    "if resample is not None:\n",
    "    waveform, sample_rate = training_unprocessed[0][0], training_unprocessed[0][1]\n",
    "\n",
    "    fn = \"sound.wav\"\n",
    "    torchaudio.save(fn, waveform, sample_rate_new)\n",
    "    ipd.Audio(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "\n",
    "    tensors = [b[0] for b in batch if b]\n",
    "    tensors = torch.nn.utils.rnn.pad_sequence(tensors, batch_first=True)\n",
    "    tensors = tensors.transpose(1, -1)\n",
    "\n",
    "    targets = [b[1] for b in batch if b]\n",
    "    target_lengths = torch.tensor(\n",
    "        [target.shape[0] for target in targets], dtype=torch.long, device=tensors.device\n",
    "    )\n",
    "    targets = torch.nn.utils.rnn.pad_sequence(targets, batch_first=True)\n",
    "\n",
    "    # print(targets.shape)\n",
    "    # print(decode(targets.tolist()))\n",
    "    \n",
    "    return tensors, targets, target_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "[Wav2Letter](https://github.com/LearnedVector/Wav2Letter/blob/master/Google%20Speech%20Command%20Example.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m): \n",
    "    if isinstance(m, nn.Linear):\n",
    "        size = m.weight.size()\n",
    "        fan_out = size[0] # number of rows\n",
    "        fan_in = size[1] # number of columns\n",
    "        variance = math.sqrt(2.0/(fan_in + fan_out))\n",
    "        m.weight.data.normal_(0.0, variance)\n",
    "\n",
    "\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Wav2Letter(nn.Module):\n",
    "    \"\"\"Wav2Letter Speech Recognition model\n",
    "        https://arxiv.org/pdf/1609.03193.pdf\n",
    "        This specific architecture accepts mfcc or power spectrums speech signals\n",
    "\n",
    "        Args:\n",
    "            num_features (int): number of mfcc features\n",
    "            num_classes (int): number of unique grapheme class labels\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv1d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv1d(num_features, 250, 48, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv1d(250, 250, 7),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv1d(250, 250, 7),\n",
    "            # nn.ReLU(),\n",
    "            nn.Conv1d(250, 2000, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(2000, 2000, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(2000, num_classes, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Forward pass through Wav2Letter network than\n",
    "            takes log probability of output\n",
    "        Args:\n",
    "            batch (int): mini batch of data\n",
    "            shape (batch, num_features, frame_len)\n",
    "        Returns:\n",
    "            Tensor with shape (batch_size, num_classes, output_len)\n",
    "        \"\"\"\n",
    "        # batch: (batch_size, num_features, seq_len)\n",
    "        y_pred = self.layers(batch)\n",
    "        # y_pred: (batch_size, num_classes, output_len)\n",
    "        y_pred = y_pred.transpose(-1, -2)\n",
    "        # y_pred: (batch_size, output_len, num_classes)\n",
    "        return nn.functional.log_softmax(y_pred, dim=-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes, num_layers, bidirectional, dropout, batch_first):\n",
    "        super().__init__()\n",
    "        \n",
    "        directions = bidirectional + 1\n",
    "\n",
    "        self.layer = nn.LSTM(\n",
    "            num_features, num_classes,\n",
    "            num_layers=num_layers, bidirectional=bidirectional, dropout=dropout, batch_first=batch_first\n",
    "        )\n",
    "        # self.hidden2class = nn.Linear(directions*num_classes, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # self.layer.flatten_parameters()\n",
    "        # print(\"forward\")\n",
    "        # batch: batch, num_features, seq_len\n",
    "        # print(batch.shape)\n",
    "        batch = batch.transpose(-1, -2).contiguous()\n",
    "        # batch: batch, seq_len, num_features\n",
    "        # print(batch.shape)\n",
    "        outputs, _ = self.layer(batch)\n",
    "        # outputs: batch, seq_len, directions*num_features\n",
    "        # outputs = self.hidden2class(outputs)\n",
    "        # outputs: batch, seq_len, num_features\n",
    "        # print(outputs.shape)\n",
    "        return nn.functional.log_softmax(outputs, dim=-1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoder(outputs):\n",
    "    \"\"\"Greedy Decoder. Returns highest probability of class labels for each timestep\n",
    "\n",
    "    Args:\n",
    "        outputs (torch.Tensor): shape (input length, batch size, number of classes (including blank))\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: class labels per time step.\n",
    "    \"\"\"\n",
    "    _, indices = topk(outputs, k=1, dim=-1)\n",
    "    return indices[..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 2, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "a = \"aaabca\"\n",
    "\n",
    "# Count bigrams\n",
    "c = Counter([\"\".join(z) for z in zip(a, a[1:])])\n",
    "\n",
    "# Encode as transition matrix\n",
    "c = [(encode(k),v) for k,v in c.items()]\n",
    "\n",
    "ind = torch.tensor(list(zip(*[a for (a,b) in c])))\n",
    "val = torch.tensor([b for (a,b) in c])\n",
    "\n",
    "torch.sparse_coo_tensor(indices=ind, values=val, size=[6,6]).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0211e-01, 2.8820e-01, 2.5007e-01,\n",
       "         1.8370e-01, 1.3226e-01, 2.4586e-01, 1.2155e-01, 4.6970e-01, 4.0684e-01,\n",
       "         2.8625e-02, 3.8320e-02, 1.6229e-01, 2.8148e-01, 1.4473e-01, 4.0300e-01,\n",
       "         1.8928e-01, 1.3971e-02, 1.3583e-01, 4.6050e-01, 1.0000e+00, 7.1878e-02,\n",
       "         4.0488e-02, 4.5780e-01, 4.5979e-05, 8.6414e-02, 9.9183e-04],\n",
       "        [0.0000e+00, 2.7440e-03, 0.0000e+00, 2.4500e-02, 1.7640e-03, 2.1756e-02,\n",
       "         7.8205e-02, 6.6641e-03, 5.8800e-04, 0.0000e+00, 7.8401e-04, 9.8001e-04,\n",
       "         0.0000e+00, 1.9600e-04, 1.1133e-01, 7.7813e-02, 5.6840e-03, 2.5480e-03,\n",
       "         1.1760e-03, 0.0000e+00, 5.3704e-02, 1.0000e+00, 4.6727e-01, 3.9200e-04,\n",
       "         6.5661e-02, 0.0000e+00, 0.0000e+00, 2.9400e-03, 0.0000e+00],\n",
       "        [0.0000e+00, 3.5371e-01, 2.4217e-03, 4.7870e-04, 9.7571e-02, 1.6769e-01,\n",
       "         2.6237e-01, 2.8441e-03, 4.2168e-02, 8.9884e-02, 8.9405e-03, 2.1173e-01,\n",
       "         3.5480e-03, 6.8877e-02, 3.4686e-01, 1.3390e-01, 1.0000e+00, 1.1968e-03,\n",
       "         8.7659e-02, 1.5488e-04, 4.6004e-01, 5.0713e-01, 6.2174e-01, 5.6628e-02,\n",
       "         1.2162e-01, 4.6434e-02, 2.6610e-03, 1.4030e-01, 7.5185e-03],\n",
       "        [0.0000e+00, 2.5627e-02, 8.9669e-04, 2.3073e-01, 2.7845e-02, 2.3597e-04,\n",
       "         1.8878e-03, 1.0000e+00, 0.0000e+00, 1.4158e-04, 6.6072e-04, 1.2459e-01,\n",
       "         2.4824e-02, 4.7194e-05, 3.4542e-01, 3.3980e-03, 1.0855e-03, 3.3635e-01,\n",
       "         9.4389e-05, 0.0000e+00, 2.0629e-01, 5.2763e-02, 2.5391e-02, 4.1267e-01,\n",
       "         2.4069e-03, 9.4389e-05, 0.0000e+00, 2.3276e-01, 0.0000e+00],\n",
       "        [0.0000e+00, 7.8083e-02, 1.1715e-03, 6.8823e-01, 5.0935e-05, 1.0722e-01,\n",
       "         2.5467e-04, 9.1693e-01, 0.0000e+00, 0.0000e+00, 9.3699e-01, 2.6873e-01,\n",
       "         0.0000e+00, 3.0826e-01, 2.1759e-01, 6.1122e-04, 3.0561e-04, 1.0000e+00,\n",
       "         1.5280e-04, 1.1053e-02, 2.2640e-01, 1.2326e-02, 3.7697e-01, 1.7486e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5960e-02, 6.1122e-04],\n",
       "        [0.0000e+00, 1.0000e+00, 2.8880e-03, 4.5032e-02, 1.6790e-04, 6.1285e-04,\n",
       "         1.4759e-02, 1.7932e-01, 1.4944e-03, 7.0520e-03, 7.2199e-04, 1.0395e-01,\n",
       "         6.2125e-04, 3.6100e-04, 1.3516e-02, 4.6929e-03, 8.1602e-03, 7.6514e-02,\n",
       "         4.0297e-04, 3.4421e-04, 3.1407e-02, 3.6620e-02, 3.5260e-04, 1.8780e-02,\n",
       "         5.2974e-03, 2.2835e-03, 0.0000e+00, 1.7580e-02, 8.3952e-06],\n",
       "        [0.0000e+00, 1.0000e+00, 7.0119e-03, 1.3883e-01, 3.6957e-03, 5.0186e-02,\n",
       "         2.4278e-01, 8.5833e-02, 2.5132e-02, 1.5032e-02, 4.8444e-03, 3.5590e-02,\n",
       "         8.9404e-04, 3.3318e-03, 9.8323e-02, 5.4843e-02, 2.3319e-01, 8.3322e-03,\n",
       "         2.7507e-02, 4.0076e-03, 3.8695e-01, 1.7630e-01, 7.4153e-02, 2.8380e-03,\n",
       "         4.6589e-02, 2.0111e-02, 2.4617e-02, 4.1188e-02, 5.9776e-04],\n",
       "        [0.0000e+00, 1.0000e+00, 6.7484e-04, 1.8239e-01, 0.0000e+00, 5.3987e-05,\n",
       "         0.0000e+00, 2.1611e-01, 1.1073e-01, 5.3987e-05, 2.6993e-05, 2.0556e-01,\n",
       "         2.6993e-05, 0.0000e+00, 7.0102e-02, 2.6993e-05, 1.6196e-04, 4.3179e-01,\n",
       "         2.6993e-05, 0.0000e+00, 1.9511e-01, 3.4552e-03, 1.0441e-01, 9.7122e-02,\n",
       "         0.0000e+00, 1.3497e-04, 0.0000e+00, 4.9938e-03, 0.0000e+00],\n",
       "        [0.0000e+00, 1.0000e+00, 4.7770e-03, 1.8123e-01, 9.6877e-04, 0.0000e+00,\n",
       "         2.7727e-03, 3.6903e-01, 7.0152e-04, 3.6045e-02, 4.1303e-01, 1.4989e-01,\n",
       "         0.0000e+00, 3.3406e-05, 9.2935e-02, 4.1089e-03, 4.7002e-02, 1.9927e-01,\n",
       "         7.6833e-04, 0.0000e+00, 2.1136e-01, 6.5509e-02, 1.4298e-02, 7.3960e-02,\n",
       "         0.0000e+00, 3.3740e-03, 0.0000e+00, 6.8482e-03, 3.0065e-04],\n",
       "        [0.0000e+00, 2.0726e-01, 9.4693e-04, 3.3956e-01, 1.7784e-03, 9.2384e-05,\n",
       "         5.7740e-04, 1.0000e+00, 1.0239e-03, 7.6986e-06, 8.4685e-05, 2.8916e-01,\n",
       "         1.3858e-04, 4.0033e-04, 2.3404e-03, 2.8870e-03, 4.0572e-03, 1.5939e-01,\n",
       "         4.6192e-05, 6.1589e-05, 2.2980e-02, 3.3335e-03, 6.3206e-02, 2.5991e-02,\n",
       "         0.0000e+00, 1.1163e-03, 0.0000e+00, 1.3072e-02, 7.6986e-06],\n",
       "        [0.0000e+00, 1.7919e-01, 1.2435e-02, 6.0627e-02, 2.6990e-02, 1.8762e-01,\n",
       "         1.6138e-01, 1.4214e-01, 8.8437e-02, 1.2241e-01, 4.8127e-04, 1.3007e-05,\n",
       "         9.1051e-05, 2.7914e-02, 1.9506e-01, 1.6873e-01, 1.0000e+00, 1.6847e-01,\n",
       "         2.6379e-02, 1.3788e-03, 1.5831e-01, 4.7813e-01, 4.8888e-01, 5.0208e-03,\n",
       "         8.4196e-02, 3.9022e-04, 9.4693e-03, 2.3413e-04, 1.3189e-02],\n",
       "        [0.0000e+00, 7.8329e-03, 5.2219e-04, 3.8068e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 7.8068e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.9817e-02,\n",
       "         0.0000e+00, 5.2219e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8930e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 8.7356e-01, 6.8884e-03, 4.5953e-02, 1.8127e-03, 4.5319e-04,\n",
       "         2.7191e-04, 1.0000e+00, 9.9701e-03, 2.6285e-03, 6.7978e-03, 4.0615e-01,\n",
       "         0.0000e+00, 8.1573e-04, 5.0032e-02, 3.1723e-03, 2.9412e-01, 2.0393e-02,\n",
       "         1.4502e-03, 0.0000e+00, 3.7161e-03, 1.3614e-01, 7.2510e-04, 5.0757e-03,\n",
       "         9.0637e-05, 8.7918e-03, 0.0000e+00, 3.0092e-02, 0.0000e+00],\n",
       "        [0.0000e+00, 8.6325e-01, 6.7713e-03, 5.1615e-01, 4.7226e-03, 9.1326e-03,\n",
       "         4.4656e-01, 1.0000e+00, 1.1171e-01, 4.9656e-03, 4.8614e-04, 6.5272e-01,\n",
       "         4.1670e-04, 4.3788e-02, 8.3659e-01, 3.0141e-02, 7.5005e-03, 4.8173e-01,\n",
       "         1.8439e-02, 0.0000e+00, 1.3369e-02, 1.1199e-01, 9.7993e-02, 1.0744e-01,\n",
       "         3.6773e-02, 2.5418e-02, 0.0000e+00, 5.2719e-01, 1.2154e-03],\n",
       "        [0.0000e+00, 6.2546e-01, 3.9618e-03, 6.1005e-01, 8.1433e-02, 1.2246e-03,\n",
       "         7.2033e-05, 1.0000e+00, 9.4724e-03, 3.6017e-05, 6.8431e-04, 4.0843e-01,\n",
       "         0.0000e+00, 0.0000e+00, 6.1228e-03, 7.4806e-02, 1.1525e-02, 4.1873e-01,\n",
       "         1.9028e-01, 0.0000e+00, 1.9449e-03, 1.0196e-01, 1.4767e-03, 1.3722e-01,\n",
       "         2.5212e-04, 6.1228e-04, 0.0000e+00, 1.9618e-01, 0.0000e+00],\n",
       "        [0.0000e+00, 1.0000e+00, 4.1849e-02, 8.8254e-02, 2.2443e-03, 1.4959e-01,\n",
       "         7.2952e-01, 3.5150e-01, 1.9008e-02, 5.0845e-01, 4.1192e-03, 1.1917e-01,\n",
       "         4.7624e-03, 3.7880e-02, 3.5649e-02, 4.0371e-03, 3.8017e-02, 2.7151e-01,\n",
       "         2.0527e-03, 4.3108e-03, 3.5718e-03, 1.4365e-01, 3.5844e-01, 2.2101e-02,\n",
       "         1.4027e-02, 3.9686e-03, 2.4496e-03, 5.2660e-02, 1.9159e-03],\n",
       "        [0.0000e+00, 1.0000e+00, 5.5692e-03, 5.1689e-02, 5.3060e-02, 7.1856e-02,\n",
       "         1.2089e-01, 2.2190e-02, 7.0640e-01, 3.3633e-02, 2.0058e-02, 6.6678e-02,\n",
       "         1.3923e-03, 8.8933e-02, 2.1215e-01, 3.8978e-01, 9.9415e-01, 2.6880e-01,\n",
       "         1.1839e-01, 1.8927e-03, 7.8267e-01, 1.9336e-01, 3.5101e-01, 9.7168e-01,\n",
       "         1.2202e-01, 3.4364e-01, 7.1573e-03, 3.4198e-02, 2.9804e-03],\n",
       "        [0.0000e+00, 4.1184e-01, 2.8694e-03, 6.2123e-01, 2.7977e-03, 1.4347e-04,\n",
       "         2.3673e-03, 1.0000e+00, 7.1736e-04, 2.8694e-04, 1.0430e-01, 3.0667e-01,\n",
       "         0.0000e+00, 2.4390e-03, 5.1456e-01, 6.4562e-03, 9.2539e-03, 6.7554e-01,\n",
       "         3.2977e-01, 0.0000e+00, 7.0545e-01, 1.2798e-01, 1.8967e-01, 1.9189e-01,\n",
       "         0.0000e+00, 2.7977e-03, 0.0000e+00, 3.2999e-02, 7.1736e-05],\n",
       "        [0.0000e+00, 5.9259e-03, 7.4074e-04, 9.8765e-04, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 1.0000e+00, 1.2448e-02, 2.6877e-01, 1.2686e-02, 4.6646e-02,\n",
       "         1.2518e-01, 9.9500e-01, 1.7822e-02, 3.5423e-02, 1.2176e-02, 3.2709e-01,\n",
       "         2.5508e-04, 3.8824e-02, 5.7989e-02, 6.5812e-02, 8.8701e-02, 3.6520e-01,\n",
       "         2.1869e-02, 4.9316e-04, 8.0658e-02, 2.0509e-01, 1.8164e-01, 6.9111e-02,\n",
       "         2.7464e-02, 9.6082e-03, 0.0000e+00, 1.4366e-01, 1.7006e-04],\n",
       "        [0.0000e+00, 1.0000e+00, 1.2498e-03, 1.1344e-01, 3.2341e-03, 3.5213e-02,\n",
       "         1.0685e-03, 2.8517e-01, 4.1214e-03, 1.4024e-03, 1.6605e-01, 1.3460e-01,\n",
       "         1.9080e-05, 2.0540e-02, 2.2753e-02, 1.6991e-02, 9.8836e-03, 1.3594e-01,\n",
       "         5.2194e-02, 2.9861e-03, 6.0103e-04, 1.2367e-01, 3.1582e-01, 8.6205e-02,\n",
       "         1.4310e-04, 1.5226e-02, 0.0000e+00, 1.1095e-02, 2.8620e-05],\n",
       "        [0.0000e+00, 7.4171e-01, 8.6711e-03, 9.6203e-02, 3.1613e-04, 1.0357e-02,\n",
       "         4.5162e-05, 2.5739e-01, 2.6495e-03, 4.1399e-04, 1.0000e+00, 1.8206e-01,\n",
       "         2.2581e-05, 3.0108e-05, 4.0766e-02, 3.3646e-03, 2.9355e-03, 3.0070e-01,\n",
       "         3.0861e-04, 0.0000e+00, 7.8717e-02, 5.2968e-02, 5.8312e-02, 4.6110e-02,\n",
       "         0.0000e+00, 2.1708e-02, 0.0000e+00, 4.3973e-02, 3.6882e-04],\n",
       "        [0.0000e+00, 4.4781e-01, 2.0900e-02, 1.5239e-01, 1.1679e-01, 2.7894e-01,\n",
       "         1.3855e-01, 2.0866e-01, 4.4212e-02, 3.7322e-01, 6.3160e-04, 1.7915e-01,\n",
       "         6.8902e-04, 7.5218e-03, 7.2238e-01, 1.6841e-01, 8.0943e-01, 1.3264e-02,\n",
       "         3.4049e-01, 2.2967e-04, 9.8369e-01, 9.0847e-01, 1.0000e+00, 2.2967e-04,\n",
       "         4.3064e-03, 4.0193e-04, 5.1677e-03, 6.2586e-03, 4.3064e-03],\n",
       "        [0.0000e+00, 2.6617e-03, 6.4016e-04, 9.3497e-02, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0182e-01,\n",
       "         0.0000e+00, 0.0000e+00, 3.3693e-05, 0.0000e+00, 1.6846e-04, 6.3713e-02,\n",
       "         0.0000e+00, 0.0000e+00, 1.3140e-03, 4.0431e-04, 0.0000e+00, 1.8194e-03,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6375e-03, 0.0000e+00],\n",
       "        [0.0000e+00, 4.5885e-01, 2.7331e-03, 1.0000e+00, 2.5568e-03, 7.0531e-04,\n",
       "         1.2784e-02, 7.2819e-01, 5.6866e-03, 8.8164e-05, 8.2266e-01, 7.1726e-01,\n",
       "         0.0000e+00, 2.6890e-03, 2.8080e-02, 7.4939e-04, 1.7897e-01, 4.2931e-01,\n",
       "         9.6980e-04, 0.0000e+00, 4.0423e-02, 4.9901e-02, 2.4686e-03, 1.8955e-03,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7747e-03, 1.3225e-04],\n",
       "        [0.0000e+00, 4.3793e-01, 9.5498e-03, 3.1378e-01, 6.8213e-04, 6.9918e-01,\n",
       "         0.0000e+00, 3.1924e-01, 8.8677e-03, 0.0000e+00, 8.7995e-02, 4.0723e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.0232e-02, 0.0000e+00, 0.0000e+00, 3.3424e-02,\n",
       "         1.0000e+00, 1.7735e-02, 0.0000e+00, 6.8213e-04, 8.0900e-01, 6.2756e-02,\n",
       "         0.0000e+00, 9.5498e-03, 0.0000e+00, 1.3643e-02, 0.0000e+00],\n",
       "        [0.0000e+00, 1.0000e+00, 8.0096e-03, 8.4459e-03, 4.1008e-03, 3.9961e-03,\n",
       "         6.6311e-04, 7.5856e-02, 1.3786e-03, 5.5841e-04, 1.0121e-03, 2.1254e-02,\n",
       "         1.7450e-05, 2.2685e-04, 8.5506e-03, 6.5613e-03, 4.5196e-03, 2.0254e-01,\n",
       "         4.6766e-03, 0.0000e+00, 4.7115e-03, 5.3991e-02, 1.3786e-02, 5.0606e-04,\n",
       "         1.3960e-04, 2.8967e-03, 1.2215e-04, 0.0000e+00, 2.9665e-04],\n",
       "        [0.0000e+00, 6.8884e-02, 3.1671e-03, 3.0721e-01, 0.0000e+00, 0.0000e+00,\n",
       "         2.3753e-03, 1.0000e+00, 0.0000e+00, 2.3753e-03, 3.9588e-03, 1.7340e-01,\n",
       "         0.0000e+00, 0.0000e+00, 6.9675e-02, 7.9177e-04, 7.1259e-03, 8.5511e-02,\n",
       "         0.0000e+00, 0.0000e+00, 2.3753e-03, 7.9177e-04, 7.9177e-04, 1.8211e-02,\n",
       "         1.5835e-02, 1.5835e-03, 0.0000e+00, 5.5424e-02, 1.1639e-01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = None\n",
    "\n",
    "for _, label in training:\n",
    "    # Count bigrams\n",
    "    count = [((a.item(), b.item())) for (a,b) in zip(label, label[1:])]\n",
    "    count = Counter(count)\n",
    "    if c is None:\n",
    "        c = count\n",
    "    else:\n",
    "        c = c + count\n",
    "\n",
    "# Encode as transition matrix\n",
    "\n",
    "ind = torch.tensor(list(zip(*[a for (a,b) in c.items()])))\n",
    "val = torch.tensor([b for (a,b) in c.items()], dtype=torch.float)\n",
    "\n",
    "transitions = torch.sparse_coo_tensor(indices=ind, values=val, size=[vocab_size,vocab_size]).coalesce().to_dense()\n",
    "transitions = (transitions/torch.max(torch.tensor(1.), transitions.max(dim=1)[0]).unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/PetrochukM/afaa3613a99a8e7213d2efdd02ae4762\n",
    "# https://github.com/napsternxg/pytorch-practice/blob/master/Viterbi%20decoding%20and%20CRF.ipynb\n",
    "\n",
    "def viterbi_decode(tag_sequence: torch.Tensor, transition_matrix: torch.Tensor, top_k: int=5):\n",
    "    \"\"\"\n",
    "    Perform Viterbi decoding in log space over a sequence given a transition matrix\n",
    "    specifying pairwise (transition) potentials between tags and a matrix of shape\n",
    "    (sequence_length, num_tags) specifying unary potentials for possible tags per\n",
    "    timestep.\n",
    "    Parameters\n",
    "    ----------\n",
    "    tag_sequence : torch.Tensor, required.\n",
    "        A tensor of shape (sequence_length, num_tags) representing scores for\n",
    "        a set of tags over a given sequence.\n",
    "    transition_matrix : torch.Tensor, required.\n",
    "        A tensor of shape (num_tags, num_tags) representing the binary potentials\n",
    "        for transitioning between a given pair of tags.\n",
    "    top_k : int, required.\n",
    "        Integer defining the top number of paths to decode.\n",
    "    Returns\n",
    "    -------\n",
    "    viterbi_path : List[int]\n",
    "        The tag indices of the maximum likelihood tag sequence.\n",
    "    viterbi_score : float\n",
    "        The score of the viterbi path.\n",
    "    \"\"\"\n",
    "    sequence_length, num_tags = list(tag_sequence.size())\n",
    "\n",
    "    path_scores = []\n",
    "    path_indices = []\n",
    "    # At the beginning, the maximum number of permutations is 1; therefore, we unsqueeze(0)\n",
    "    # to allow for 1 permutation.\n",
    "    path_scores.append(tag_sequence[0, :].unsqueeze(0))\n",
    "    # assert path_scores[0].size() == (n_permutations, num_tags)\n",
    "\n",
    "    # Evaluate the scores for all possible paths.\n",
    "    for timestep in range(1, sequence_length):\n",
    "        # Add pairwise potentials to current scores.\n",
    "        # assert path_scores[timestep - 1].size() == (n_permutations, num_tags)\n",
    "        summed_potentials = path_scores[timestep - 1].unsqueeze(2) + transition_matrix\n",
    "        summed_potentials = summed_potentials.view(-1, num_tags)\n",
    "\n",
    "        # Best pairwise potential path score from the previous timestep. \n",
    "        max_k = min(summed_potentials.size()[0], top_k)\n",
    "        scores, paths = torch.topk(summed_potentials, k=max_k, dim=0)\n",
    "        # assert scores.size() == (n_permutations, num_tags)\n",
    "        # assert paths.size() == (n_permutations, num_tags)\n",
    "\n",
    "        scores = tag_sequence[timestep, :] + scores\n",
    "        # assert scores.size() == (n_permutations, num_tags)\n",
    "        path_scores.append(scores)\n",
    "        path_indices.append(paths.squeeze())\n",
    "\n",
    "    # Construct the most likely sequence backwards.\n",
    "    path_scores = path_scores[-1].view(-1)\n",
    "    max_k = min(path_scores.size()[0], top_k)\n",
    "    viterbi_scores, best_paths = torch.topk(path_scores, k=max_k, dim=0)\n",
    "    viterbi_paths = []\n",
    "    for i in range(max_k):\n",
    "        viterbi_path = [best_paths[i]]\n",
    "        for backward_timestep in reversed(path_indices):\n",
    "            viterbi_path.append(int(backward_timestep.view(-1)[viterbi_path[-1]]))\n",
    "        # Reverse the backward path.\n",
    "        viterbi_path.reverse()\n",
    "        # Viterbi paths uses (num_tags * n_permutations) nodes; therefore, we need to modulo.\n",
    "        viterbi_path = [j % num_tags for j in viterbi_path]\n",
    "        viterbi_paths.append(viterbi_path)\n",
    "    return viterbi_paths, viterbi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://martin-thoma.com/word-error-rate-calculation/\n",
    "\n",
    "def compute_wer(r, h):\n",
    "    \"\"\"\n",
    "    Calculation of WER with Levenshtein distance.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialisation\n",
    "    # import numpy\n",
    "    # d = numpy.zeros((len(r)+1, len(h)+1), dtype=numpy.uint8)\n",
    "    # d[0,:] = range(len(h)+1)\n",
    "    # d[:,0] = range(len(r)+1)\n",
    "    \n",
    "    # initialisation\n",
    "    d = torch.zeros((len(r)+1, len(h)+1), dtype=torch.long)\n",
    "    d[0,:] = torch.range(0,len(h), dtype=torch.long)\n",
    "    d[:,0] = torch.range(0,len(r), dtype=torch.long)\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i,j] = d[i-1,j-1]\n",
    "            else:\n",
    "                substitution = d[i-1,j-1] + 1\n",
    "                insertion    = d[i,j-1] + 1\n",
    "                deletion     = d[i-1,j] + 1\n",
    "                d[i,j] = min(substitution, insertion, deletion)\n",
    "\n",
    "    return d[len(r)][len(h)].item()/len(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445 42\n"
     ]
    }
   ],
   "source": [
    "loader_training = DataLoader(\n",
    "    training, batch_size=batch_size, collate_fn=collate_fn, **data_loader_training_params\n",
    ")\n",
    "\n",
    "loader_validation = DataLoader(\n",
    "    validation, batch_size=batch_size, collate_fn=collate_fn, **data_loader_validation_params\n",
    ")\n",
    "\n",
    "print(len(loader_training), len(loader_validation))\n",
    "\n",
    "# num_features = next(iter(loader_training))[0].shape[1]\n",
    "# print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Letter(num_features, vocab_size)\n",
    "# model = LSTMModel(num_features, vocab_size, **lstm_params)\n",
    "\n",
    "model = torch.jit.script(model)\n",
    "model = nn.DataParallel(model) if num_devices > 1 else model\n",
    "model = model.to(device, non_blocking=non_blocking)\n",
    "# model.apply(weight_init)\n",
    "\n",
    "optimizer = Optimizer(model.parameters(), **optimizer_params)\n",
    "# scheduler = ExponentialLR(optimizer, gamma=gamma)\n",
    "# scheduler = ReduceLROnPlateau(optimizer)\n",
    "\n",
    "criterion = torch.nn.CTCLoss(zero_infinity=zero_infinity)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = torch.nn.NLLLoss()\n",
    "\n",
    "best_loss = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_loss(inputs, targets, target_lengths):\n",
    "\n",
    "    inputs = inputs.to(device, non_blocking=non_blocking)\n",
    "    targets = targets.to(device, non_blocking=non_blocking)\n",
    "    \n",
    "    # keep batch first for data parallel\n",
    "    outputs = model(inputs).transpose(0, 1)\n",
    "\n",
    "    this_batch_size = outputs.shape[1]\n",
    "    seq_len = outputs.shape[0]\n",
    "    input_lengths = torch.full((this_batch_size,), seq_len, dtype=torch.long, device=outputs.device)\n",
    "    \n",
    "    # CTC    \n",
    "    # outputs: input length, batch size, number of classes (including blank)\n",
    "    # targets: batch size, max target length\n",
    "    # input_lengths: batch size\n",
    "    # target_lengths: batch size\n",
    "\n",
    "    return criterion(outputs, targets, input_lengths, target_lengths)\n",
    "\n",
    "\n",
    "def forward_decode_wer(inputs, targets):\n",
    "\n",
    "    import statistics\n",
    "    \n",
    "    output = model(inputs)\n",
    "\n",
    "    # output = output[0, :, :].unsqueeze(0)\n",
    "    # targets = targets[0, ...].unsqueeze(0)\n",
    "\n",
    "    # output = output.transpose(0, 1)\n",
    "    output = greedy_decoder(output)\n",
    "\n",
    "    output = decode(output.tolist())\n",
    "    target = decode(targets.tolist())\n",
    "    \n",
    "    print_length = 20\n",
    "    output_print = output[0].ljust(print_length)[:print_length]\n",
    "    target_print = target[0].ljust(print_length)[:print_length]\n",
    "    print(f\"Epoch: {epoch:4}   Target: {target_print}   Output: {output_print}\")\n",
    "\n",
    "    output = [o.split(char_space) for o in output]\n",
    "    target = [o.split(char_space) for o in target]\n",
    "    \n",
    "    wers = [compute_wer(a, b) for a, b in zip(output, target)]\n",
    "    score = statistics.mean(wers)\n",
    "    # score = statistics.median(wers)\n",
    "    print(f\"Epoch: {epoch:4}   WER: {score:1.5f}\")\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edeced9b55a84c72837be3d8059f207e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0   Gradient: 1.9691160315727263\n",
      "Epoch:    0   Target: we will hunt wolves    Output:                     \n",
      "Epoch:    0   WER: 21.21875\n",
      "Epoch:    0   Train: 3.70042   Validation: 2.96873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   10   Gradient: 1.9157189685401814\n",
      "Epoch:   10   Target: we will hunt wolves    Output: welehunmolse  the co\n",
      "Epoch:   10   WER: 0.94321\n",
      "Epoch:   10   Train: 0.78294   Validation: 0.89691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   30   Gradient: 1.2472710668181826\n",
      "Epoch:   30   Target: we will hunt wolves    Output: wili  hhunt mols the\n",
      "Epoch:   30   WER: 0.89873\n",
      "Epoch:   30   Train: 0.16472   Validation: 1.19151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   60   Gradient: 1.5137953036347327\n",
      "Epoch:   60   Target: we will hunt wolves    Output: whiilia hhunt mollee\n",
      "Epoch:   60   WER: 0.93410\n",
      "Epoch:   60   Train: 0.04511   Validation: 2.10709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   70   Gradient: 0.8359894537585131\n",
      "Epoch:   70   Target: we will hunt wolves    Output: willhhunt boles the \n",
      "Epoch:   70   WER: 0.92354\n",
      "Epoch:   70   Train: 0.03829   Validation: 2.18692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  100   Gradient: 2.386884791298679\n",
      "Epoch:  100   Target: we will hunt wolves    Output: liilhhunn olles the \n",
      "Epoch:  100   WER: 0.92445\n",
      "Epoch:  100   Train: 0.02705   Validation: 2.41518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  110   Gradient: 0.9284177462004661\n",
      "Epoch:  110   Target: we will hunt wolves    Output: whit  lhhunnnollees \n",
      "Epoch:  110   WER: 0.93705\n",
      "Epoch:  110   Train: 0.02484   Validation: 2.43363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  140   Gradient: 0.8091099427005691\n",
      "Epoch:  140   Target: we will hunt wolves    Output: willl hhunt  wolles \n",
      "Epoch:  140   WER: 0.93062\n",
      "Epoch:  140   Train: 0.01922   Validation: 2.50753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  170   Gradient: 0.6786116151947998\n",
      "Epoch:  170   Target: we will hunt wolves    Output: wi' hhunk oles the  \n",
      "Epoch:  170   WER: 0.92811\n",
      "Epoch:  170   Train: 0.01751   Validation: 2.50675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  190   Gradient: 0.6649078845399577\n",
      "Epoch:  190   Target: we will hunt wolves    Output: wi'ill hunwolles the\n",
      "Epoch:  190   WER: 0.91573\n",
      "Epoch:  190   Train: 0.01571   Validation: 2.55924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  199   Gradient: 0.8413622720888496\n",
      "Epoch:  199   Target: we will hunt wolves    Output: wiil hun molles the \n",
      "Epoch:  199   WER: 0.92344\n",
      "Epoch:  199   Train: 0.01665   Validation: 2.52914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sum_loss_training = []\n",
    "sum_loss_validation = []\n",
    "gradient_norm = []\n",
    "gradient_norm_training = []\n",
    "wer_validation = []\n",
    "\n",
    "with tqdm(total=max_epoch, unit_scale=1) as pbar:\n",
    "    for epoch in range(max_epoch):\n",
    "        model.train()\n",
    "\n",
    "        sum_loss = 0.\n",
    "        for inputs, targets, target_lengths in loader_training:\n",
    "\n",
    "            loss = forward_and_loss(inputs, targets, target_lengths)\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if clip_norm > 0:\n",
    "                total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
    "                gradient_norm_training.append((epoch, total_norm))\n",
    "                print(f\"Epoch: {epoch:4}   Gradient: {total_norm:4.5f}\")\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1/len(loader_training))\n",
    "\n",
    "        # Average loss\n",
    "        sum_loss = sum_loss / len(loader_training)\n",
    "        sum_loss_training.append((epoch, sum_loss))\n",
    "        sum_loss_str = f\"Epoch: {epoch:4}   Train: {sum_loss:4.5f}\"\n",
    "        \n",
    "        # scheduler.step()\n",
    "        # scheduler.step(sum_loss)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            if not epoch % mod_epoch or epoch == max_epoch-1:\n",
    "\n",
    "                total_norm = 0.\n",
    "                for p in list(filter(lambda p: p.grad is not None, model.parameters())):\n",
    "                    total_norm += p.grad.data.norm(2).item() ** 2                    \n",
    "                total_norm = total_norm ** (1. / 2)\n",
    "                gradient_norm.append(total_norm)\n",
    "                print(f\"Epoch: {epoch:4}   Gradient: {total_norm}\")\n",
    "                \n",
    "                # Switch to evaluation mode\n",
    "                model.eval()\n",
    "        \n",
    "                sum_loss = 0.\n",
    "                for inputs, targets, target_lengths in loader_validation:\n",
    "                    sum_loss += forward_and_loss(inputs, targets, target_lengths).item()\n",
    "\n",
    "                # Average loss\n",
    "                sum_loss = sum_loss / len(loader_validation)\n",
    "                sum_loss_validation.append((epoch, sum_loss))\n",
    "                sum_loss_str += f\"   Validation: {sum_loss:.5f}\"\n",
    "\n",
    "                wer = forward_decode_wer(inputs, targets)\n",
    "                wer_validation.append((epoch, wer))\n",
    "\n",
    "                print(sum_loss_str)\n",
    "\n",
    "                if sum_loss < best_loss:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), f\"./model.{dtstamp}.{epoch}.ph\")\n",
    "                    best_loss = sum_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7b0c0c15d0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(*zip(*wer_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7b040c4350>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(*zip(*sum_loss_training), label=\"training\")\n",
    "plt.plot(*zip(*sum_loss_validation), label=\"validation\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7b0404dc90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_loss_training = [(a, math.log(b)) for (a,b) in sum_loss_training]\n",
    "sum_loss_validation = [(a, math.log(b)) for (a,b) in sum_loss_validation]\n",
    "\n",
    "plt.plot(*zip(*sum_loss_training), label=\"training\")\n",
    "plt.plot(*zip(*sum_loss_validation), label=\"validation\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         939883672 function calls (904098273 primitive calls) in 71437.558 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2659 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        7    0.000    0.000 71437.555 10205.365 base_events.py:1686(_run_once)\n",
      "      115    0.000    0.000 71437.555  621.196 events.py:86(_run)\n",
      "      115    0.000    0.000 71437.555  621.196 {method 'run' of 'Context' objects}\n",
      "       88    0.000    0.000 71437.555  811.790 ioloop.py:735(_run_callback)\n",
      "     63/7    0.001    0.000 71437.555 10205.365 gen.py:716(run)\n",
      "   100/27    0.000    0.000 71437.554 2645.835 {method 'send' of 'generator' objects}\n",
      "        5    0.000    0.000 71437.552 14287.510 ioloop.py:690(<lambda>)\n",
      "        5    0.000    0.000 71437.552 14287.510 gen.py:784(inner)\n",
      "    80/22    0.001    0.000 71437.550 3247.161 gen.py:184(wrapper)\n",
      "       60    0.000    0.000 71437.549 1190.626 kernelbase.py:347(process_one)\n",
      "       40    0.001    0.000 71437.548 1785.939 kernelbase.py:225(dispatch_shell)\n",
      "307856/60    0.234    0.000 71437.529 1190.625 {built-in method builtins.next}\n",
      "    60/26    0.000    0.000 71437.520 2747.597 gen.py:700(__init__)\n",
      "       40    0.001    0.000 71437.516 1785.938 kernelbase.py:512(execute_request)\n",
      "       20    0.000    0.000 71437.514 3571.876 kernelbase.py:363(dispatch_queue)\n",
      "       20    0.000    0.000 71437.475 3571.874 ipkernel.py:262(do_execute)\n",
      "       20    0.000    0.000 71437.424 3571.871 zmqshell.py:534(run_cell)\n",
      "       20    0.000    0.000 71437.423 3571.871 interactiveshell.py:2831(run_cell)\n",
      "       20    0.000    0.000 71436.706 3571.835 interactiveshell.py:2865(_run_cell)\n",
      "       20    0.000    0.000 71436.660 3571.833 async_helpers.py:58(_pseudo_sync_runner)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), f\"./model.{dtstamp}.{epoch}.ph\")\n",
    "\n",
    "# Print performance\n",
    "pr.disable()\n",
    "s = StringIO()\n",
    "ps = pstats.Stats(pr, stream=s).strip_dirs().sort_stats(\"cumtime\").print_stats(20)\n",
    "print(s.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
