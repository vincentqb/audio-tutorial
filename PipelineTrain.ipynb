{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import cProfile\n",
    "import hashlib\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import pstats\n",
    "import string\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn, topk\n",
    "from torch.optim import Adadelta, Adam, SGD\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchaudio.datasets import SPEECHCOMMANDS, LIBRISPEECH\n",
    "from torchaudio.transforms import MFCC, Resample\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Empty CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Profiling performance\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GPUs\n",
      "200311.142258\n"
     ]
    }
   ],
   "source": [
    "audio_backend = \"soundfile\"\n",
    "torchaudio.set_audio_backend(audio_backend)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_devices = torch.cuda.device_count()\n",
    "# num_devices = 1\n",
    "print(num_devices, \"GPUs\")\n",
    "\n",
    "# max number of sentences per batch\n",
    "# batch_size = 2048\n",
    "# batch_size = 512\n",
    "# batch_size = 256\n",
    "batch_size = 64\n",
    "\n",
    "training_percentage = 90.\n",
    "validation_percentage = 5.\n",
    "\n",
    "data_loader_training_params = {\n",
    "    \"num_workers\": 0,\n",
    "    \"pin_memory\": False,\n",
    "    \"shuffle\": True,\n",
    "    \"drop_last\": True,\n",
    "}\n",
    "data_loader_validation_params = data_loader_training_params.copy()\n",
    "data_loader_validation_params[\"shuffle\"] = False\n",
    "\n",
    "non_blocking = data_loader_training_params[\"pin_memory\"]\n",
    "\n",
    "\n",
    "# text preprocessing\n",
    "\n",
    "char_null = \"-\"\n",
    "char_pad = \"*\"\n",
    "char_apostrophe = \"'\"\n",
    "\n",
    "labels = [char_null + char_pad + char_apostrophe + string.ascii_lowercase]\n",
    "\n",
    "# excluded_dir = [\"_background_noise_\"]\n",
    "# folder_speechcommands = './SpeechCommands/speech_commands_v0.02'\n",
    "# labels = [char_null, char_pad] + [d for d in next(os.walk(folder_speechcommands))[1] if d not in excluded_dir]\n",
    "\n",
    "\n",
    "# audio\n",
    "\n",
    "sample_rate_original = 16000\n",
    "sample_rate_new = 8000\n",
    "resample = Resample(sample_rate_original, sample_rate_new)\n",
    "# resample = None\n",
    "\n",
    "n_mfcc = 13\n",
    "melkwargs = {\n",
    "    'n_fft': 512,\n",
    "    'n_mels': 20,\n",
    "    'hop_length': 80,  # (160, 80)\n",
    "}\n",
    "mfcc = MFCC(sample_rate=sample_rate_original, n_mfcc=n_mfcc, melkwargs=melkwargs).to(device)\n",
    "# mfcc = None\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "optimizer_params_adadelta = {\n",
    "    \"lr\": 1.0,\n",
    "    \"eps\": 1e-8,\n",
    "    \"rho\": 0.95,\n",
    "    # \"weight_decay\": .01,\n",
    "}\n",
    "\n",
    "optimizer_params_adam = {\n",
    "    \"lr\": .05,\n",
    "    \"eps\": 1e-8,\n",
    "    \"weight_decay\": .01,\n",
    "}\n",
    "\n",
    "optimizer_params_sgd = {\n",
    "    \"lr\": .001,\n",
    "    \"weight_decay\": .0001,\n",
    "}\n",
    "\n",
    "Optimizer = Adadelta\n",
    "optimizer_params = optimizer_params_adadelta\n",
    "\n",
    "gamma = 0.95\n",
    "\n",
    "\n",
    "# Model\n",
    "\n",
    "lstm_params = {\n",
    "    \"num_layers\": 3,\n",
    "    \"batch_first\": False,\n",
    "    \"bidirectional\": False,\n",
    "    \"dropout\": 0.,\n",
    "}\n",
    "\n",
    "clip_norm = 0.  # 10.\n",
    "\n",
    "zero_infinity = False\n",
    "\n",
    "max_epoch = 200\n",
    "mod_epoch = 10\n",
    "\n",
    "dtstamp = datetime.now().strftime(\"%y%m%d.%H%M%S\")\n",
    "print(dtstamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "class Coder:\n",
    "    def __init__(self, labels):\n",
    "        labels = list(collections.OrderedDict.fromkeys(list(\"\".join(labels))))\n",
    "        self.length = len(labels)\n",
    "        enumerated = list(enumerate(labels))\n",
    "        flipped = [(sub[1], sub[0]) for sub in enumerated]\n",
    "\n",
    "        d1 = collections.OrderedDict(enumerated)\n",
    "        d2 = collections.OrderedDict(flipped)\n",
    "        self.mapping = {**d1, **d2}\n",
    "\n",
    "    def _map(self, iterable):\n",
    "        # iterable to iterable\n",
    "        return [self.mapping[i] for i in iterable]\n",
    "\n",
    "    def encode(self, iterable):\n",
    "        if isinstance(iterable[0], list):\n",
    "            return [self.encode(i) for i in iterable]\n",
    "        else:\n",
    "            return self._map(iterable)\n",
    "\n",
    "    def decode(self, tensor):\n",
    "        if isinstance(tensor[0], list):\n",
    "            return [self.decode(t) for t in tensor]\n",
    "        else:\n",
    "            return \"\".join(self._map(tensor))\n",
    "\n",
    "\n",
    "coder = Coder(labels)\n",
    "encode = coder.encode\n",
    "decode = coder.decode\n",
    "vocab_size = coder.length\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterableMemoryCache:\n",
    "\n",
    "    def __init__(self, iterable):\n",
    "        self.iterable = iterable\n",
    "        self._iter = iter(iterable)\n",
    "        self._done = False\n",
    "        self._values = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self._done:\n",
    "            return iter(self._values)\n",
    "        return itertools.chain(self._values, self._gen_iter())\n",
    "\n",
    "    def _gen_iter(self):\n",
    "        for new_values in self._iter:\n",
    "            self._values.append(new_value)\n",
    "            yield new_value\n",
    "        self._done = True\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._iterable)\n",
    "\n",
    "\n",
    "class MapMemoryCache(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Wrap a dataset so that, whenever a new item is returned, it is saved to memory.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self._cache = [None] * len(dataset)\n",
    "\n",
    "    def __getitem__(self, n):\n",
    "        if self._cache[n]:\n",
    "            return self._cache[n]\n",
    "\n",
    "        item = self.dataset[n]\n",
    "        self._cache[n] = item\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "class Processed(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, process_datapoint, dataset):\n",
    "        self.process_datapoint = process_datapoint\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def __getitem__(self, n):\n",
    "        try:\n",
    "            item = self.dataset[n]\n",
    "            return self.process_datapoint(item)\n",
    "        except (FileNotFoundError, RuntimeError):\n",
    "            return None\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            item = next(self.dataset)\n",
    "            return self.process_datapoint(item)\n",
    "        except (FileNotFoundError, RuntimeError):\n",
    "            return self.__next__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datapoint(item):\n",
    "    transformed = item[0].to(device, non_blocking=non_blocking)\n",
    "    target = item[2].lower().replace(\" \", char_pad)\n",
    "    # target = \"\".join(filter(str.isalnum, target))\n",
    "    target = \"\".join(c for c in target if c.isalnum() or c == char_pad)\n",
    "    # pick first channel, apply mfcc, tranpose for pad_sequence\n",
    "    transformed = mfcc(transformed)\n",
    "    transformed = transformed[0, ...].transpose(0, -1)\n",
    "    # transformed = transformed.view(-1, 1)\n",
    "    target = encode(target)\n",
    "    target = torch.tensor(target, dtype=torch.long, device=transformed.device)\n",
    "    return transformed, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets():\n",
    "\n",
    "    root = \"./\"\n",
    "    def create(tag):\n",
    "        data = LIBRISPEECH(root, tag, download=True)\n",
    "        data = Processed(process_datapoint, data)\n",
    "        data = MapMemoryCache(data)\n",
    "        return data\n",
    "\n",
    "    return create(\"train-clean-100\"), create(\"dev-clean\"), None\n",
    "\n",
    "\n",
    "training, validation, _ = datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_set(filename, validation_percentage, testing_percentage):\n",
    "    \"\"\"Determines which data partition the file should belong to.\n",
    "\n",
    "    We want to keep files in the same training, validation, or testing sets even\n",
    "    if new ones are added over time. This makes it less likely that testing\n",
    "    samples will accidentally be reused in training when long runs are restarted\n",
    "    for example. To keep this stability, a hash of the filename is taken and used\n",
    "    to determine which set it should belong to. This determination only depends on\n",
    "    the name and the set proportions, so it won't change as other files are added.\n",
    "\n",
    "    It's also useful to associate particular files as related (for example words\n",
    "    spoken by the same person), so anything after '_nohash_' in a filename is\n",
    "    ignored for set determination. This ensures that 'bobby_nohash_0.wav' and\n",
    "    'bobby_nohash_1.wav' are always in the same set, for example.\n",
    "\n",
    "    Args:\n",
    "        filename: File path of the data sample.\n",
    "        validation_percentage: How much of the data set to use for validation.\n",
    "        testing_percentage: How much of the data set to use for testing.\n",
    "\n",
    "    Returns:\n",
    "        String, one of 'training', 'validation', or 'testing'.\n",
    "    \"\"\"\n",
    "    \n",
    "    MAX_NUM_WAVS_PER_CLASS = 2**27 - 1  # ~134M\n",
    "\n",
    "    base_name = os.path.basename(filename)\n",
    "\n",
    "    # We want to ignore anything after '_nohash_' in the file name when\n",
    "    # deciding which set to put a wav in, so the data set creator has a way of\n",
    "    # grouping wavs that are close variations of each other.\n",
    "    hash_name = re.sub(r'_nohash_.*$', '', base_name).encode(\"utf-8\")\n",
    "    \n",
    "    # This looks a bit magical, but we need to decide whether this file should\n",
    "    # go into the training, testing, or validation sets, and we want to keep\n",
    "    # existing files in the same set even if more files are subsequently\n",
    "    # added.\n",
    "    # To do that, we need a stable way of deciding based on just the file name\n",
    "    # itself, so we do a hash of that and then use that to generate a\n",
    "    # probability value that we use to assign it.\n",
    "    hash_name_hashed = hashlib.sha1(hash_name).hexdigest()\n",
    "    percentage_hash = ((int(hash_name_hashed, 16) % (MAX_NUM_WAVS_PER_CLASS + 1)) * (100.0 / MAX_NUM_WAVS_PER_CLASS))\n",
    "    \n",
    "    if percentage_hash < validation_percentage:\n",
    "        result = 'validation'\n",
    "    elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "        result = 'testing'\n",
    "    else:\n",
    "        result = 'training'\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def filter_speechcommands(tag, training_percentage, data):\n",
    "    if training_percentage < 100.:\n",
    "            testing_percentage = (100. - training_percentage - validation_percentage)\n",
    "            which_set_filter = lambda x: which_set(x, validation_percentage, testing_percentage) == tag\n",
    "            data._walker = list(filter(which_set_filter, data._walker))\n",
    "    return data\n",
    "\n",
    "\n",
    "def datasets():\n",
    "\n",
    "    root = \"./\"\n",
    "    def create(tag):\n",
    "        data = SPEECHCOMMANDS(root, download=True)\n",
    "        data = filter_speechcommands(tag, training_percentage, data)\n",
    "        data = Processed(process_datapoint, data)\n",
    "        data = MapMemoryCache(data)\n",
    "        return data\n",
    "\n",
    "    return create(\"training\"), create(\"validation\"), create(\"testing\")\n",
    "\n",
    "\n",
    "# training, validation, _ = datasets()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "training_unprocessed = SPEECHCOMMANDS(\"./\", download=True)\n",
    "training_unprocessed = filter_speechcommands(training_percentage, training_unprocessed)\n",
    "\n",
    "counter = Counter([t[2] for t in training_unprocessed])\n",
    "counter = OrderedDict(counter.most_common())\n",
    "\n",
    "plt.bar(counter.keys(), counter.values(), align='center')\n",
    "\n",
    "if resample is not None:\n",
    "    waveform, sample_rate = training_unprocessed[0][0], training_unprocessed[0][1]\n",
    "\n",
    "    fn = \"sound.wav\"\n",
    "    torchaudio.save(fn, waveform, sample_rate_new)\n",
    "    ipd.Audio(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "\n",
    "    tensors = [b[0] for b in batch if b]\n",
    "    tensors = torch.nn.utils.rnn.pad_sequence(tensors, batch_first=True)\n",
    "    tensors = tensors.transpose(1, -1)\n",
    "\n",
    "    targets = [b[1] for b in batch if b]\n",
    "    target_lengths = torch.tensor(\n",
    "        [target.shape[0] for target in targets], dtype=torch.long, device=tensors.device\n",
    "    )\n",
    "    targets = torch.nn.utils.rnn.pad_sequence(targets, batch_first=True)\n",
    "\n",
    "    # print(targets.shape)\n",
    "    # print(decode(targets.tolist()))\n",
    "    \n",
    "    return tensors, targets, target_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "[Wav2Letter](https://github.com/LearnedVector/Wav2Letter/blob/master/Google%20Speech%20Command%20Example.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m): \n",
    "    if isinstance(m, nn.Linear):\n",
    "        size = m.weight.size()\n",
    "        fan_out = size[0] # number of rows\n",
    "        fan_in = size[1] # number of columns\n",
    "        variance = math.sqrt(2.0/(fan_in + fan_out))\n",
    "        m.weight.data.normal_(0.0, variance)\n",
    "\n",
    "\n",
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Wav2Letter(nn.Module):\n",
    "    \"\"\"Wav2Letter Speech Recognition model\n",
    "        https://arxiv.org/pdf/1609.03193.pdf\n",
    "        This specific architecture accepts mfcc or power spectrums speech signals\n",
    "\n",
    "        Args:\n",
    "            num_features (int): number of mfcc features\n",
    "            num_classes (int): number of unique grapheme class labels\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv1d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv1d(num_features, 250, 48, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(250, 250, 7),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv1d(250, 250, 7),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv1d(250, 250, 7),\n",
    "            # nn.ReLU(),\n",
    "            nn.Conv1d(250, 2000, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(2000, 2000, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(2000, num_classes, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Forward pass through Wav2Letter network than\n",
    "            takes log probability of output\n",
    "        Args:\n",
    "            batch (int): mini batch of data\n",
    "            shape (batch, num_features, frame_len)\n",
    "        Returns:\n",
    "            Tensor with shape (batch_size, num_classes, output_len)\n",
    "        \"\"\"\n",
    "        # batch: (batch_size, num_features, seq_len)\n",
    "        y_pred = self.layers(batch)\n",
    "        # y_pred: (batch_size, num_classes, output_len)\n",
    "        y_pred = y_pred.transpose(-1, -2)\n",
    "        # y_pred: (batch_size, output_len, num_classes)\n",
    "        return nn.functional.log_softmax(y_pred, dim=-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_classes, num_layers, bidirectional, dropout, batch_first):\n",
    "        super().__init__()\n",
    "        \n",
    "        directions = bidirectional + 1\n",
    "\n",
    "        self.layer = nn.LSTM(\n",
    "            num_features, num_classes,\n",
    "            num_layers=num_layers, bidirectional=bidirectional, dropout=dropout, batch_first=batch_first\n",
    "        )\n",
    "        # self.hidden2class = nn.Linear(directions*num_classes, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # self.layer.flatten_parameters()\n",
    "        # print(\"forward\")\n",
    "        # batch: batch, num_features, seq_len\n",
    "        # print(batch.shape)\n",
    "        batch = batch.transpose(-1, -2).contiguous()\n",
    "        # batch: batch, seq_len, num_features\n",
    "        # print(batch.shape)\n",
    "        outputs, _ = self.layer(batch)\n",
    "        # outputs: batch, seq_len, directions*num_features\n",
    "        # outputs = self.hidden2class(outputs)\n",
    "        # outputs: batch, seq_len, num_features\n",
    "        # print(outputs.shape)\n",
    "        return nn.functional.log_softmax(outputs, dim=-1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoder(outputs):\n",
    "    \"\"\"Greedy Decoder. Returns highest probability of class labels for each timestep\n",
    "\n",
    "    Args:\n",
    "        outputs (torch.Tensor): shape (input length, batch size, number of classes (including blank))\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: class labels per time step.\n",
    "    \"\"\"\n",
    "    _, indices = topk(outputs, k=1, dim=-1)\n",
    "    return indices[..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445 42\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "loader_training = DataLoader(\n",
    "    training, batch_size=batch_size, collate_fn=collate_fn, **data_loader_training_params\n",
    ")\n",
    "\n",
    "loader_validation = DataLoader(\n",
    "    validation, batch_size=batch_size, collate_fn=collate_fn, **data_loader_validation_params\n",
    ")\n",
    "\n",
    "print(len(loader_training), len(loader_validation))\n",
    "\n",
    "num_features = next(iter(loader_training))[0].shape[1]\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Letter(num_features, vocab_size)\n",
    "# model = LSTMModel(num_features, vocab_size, **lstm_params)\n",
    "\n",
    "model = torch.jit.script(model)\n",
    "model = nn.DataParallel(model) if num_devices > 1 else model\n",
    "model = model.to(device, non_blocking=non_blocking)\n",
    "# model.apply(weight_init)\n",
    "\n",
    "optimizer = Optimizer(model.parameters(), **optimizer_params)\n",
    "# scheduler = ExponentialLR(optimizer, gamma=gamma)\n",
    "# scheduler = ReduceLROnPlateau(optimizer)\n",
    "\n",
    "criterion = torch.nn.CTCLoss(zero_infinity=zero_infinity)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = torch.nn.NLLLoss()\n",
    "\n",
    "best_loss = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_loss(inputs, targets, target_lengths):\n",
    "\n",
    "    inputs = inputs.to(device, non_blocking=non_blocking)\n",
    "    targets = targets.to(device, non_blocking=non_blocking)\n",
    "    \n",
    "    # keep batch first for data parallel\n",
    "    outputs = model(inputs).transpose(0, 1)\n",
    "\n",
    "    this_batch_size = outputs.shape[1]\n",
    "    seq_len = outputs.shape[0]\n",
    "    input_lengths = torch.full((this_batch_size,), seq_len, dtype=torch.long, device=outputs.device)\n",
    "    \n",
    "    # CTC    \n",
    "    # outputs: input length, batch size, number of classes (including blank)\n",
    "    # targets: batch size, max target length\n",
    "    # input_lengths: batch size\n",
    "    # target_lengths: batch size\n",
    "\n",
    "    return criterion(outputs, targets, input_lengths, target_lengths)\n",
    "\n",
    "\n",
    "def forward_and_decode(inputs, targets):\n",
    "    output = model(inputs)\n",
    "    output = output.transpose(0, 1)\n",
    "    output = output[:, 0, :]\n",
    "    output = greedy_decoder(output)\n",
    "    output = decode(output.tolist())\n",
    "    target = decode(targets.tolist()[0])\n",
    "\n",
    "    print_length = 20\n",
    "    output = output.ljust(print_length)[:print_length]\n",
    "    target = target.ljust(print_length)[:print_length]\n",
    "\n",
    "    return f\"Epoch: {epoch:4}   Target: {target}   Output: {output}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cffb29a85d414c950230c94dbacb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0   Gradient: 6.186310441814044\n",
      "Epoch:    0   Target: affairs*connected*wi   Output: --------------------\n",
      "Epoch:    0   Target: we*will*hunt*wolves*   Output: --------------------\n",
      "Epoch:    0   Train: 3.73166   Validation: 2.97911\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-24b53ead0ac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msum_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/audio-built/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/audio-built/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/audio-built/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-c72d9602cce3>\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     target_lengths = torch.tensor(\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sum_loss_training = []\n",
    "sum_loss_validation = []\n",
    "gradient_norm = []\n",
    "gradient_norm_training = []\n",
    "\n",
    "with tqdm(total=max_epoch, unit_scale=1) as pbar:\n",
    "    for epoch in range(max_epoch):\n",
    "        model.train()\n",
    "\n",
    "        sum_loss = 0.\n",
    "        for inputs, targets, target_lengths in loader_training:\n",
    "\n",
    "            loss = forward_and_loss(inputs, targets, target_lengths)\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if clip_norm > 0:\n",
    "                total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
    "                gradient_norm_training.append((epoch, total_norm))\n",
    "                print(f\"Epoch: {epoch:4}   Gradient: {total_norm:4.5f}\")\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1/len(loader_training))\n",
    "\n",
    "        # Average loss\n",
    "        sum_loss = sum_loss / len(loader_training)\n",
    "        sum_loss_training.append((epoch, sum_loss))\n",
    "        sum_loss_str = f\"Epoch: {epoch:4}   Train: {sum_loss:4.5f}\"\n",
    "        \n",
    "        # scheduler.step()\n",
    "        # scheduler.step(sum_loss)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            if not epoch % mod_epoch or epoch == max_epoch-1:\n",
    "\n",
    "                total_norm = 0.\n",
    "                for p in list(filter(lambda p: p.grad is not None, model.parameters())):\n",
    "                    total_norm += p.grad.data.norm(2).item() ** 2                    \n",
    "                total_norm = total_norm ** (1. / 2)\n",
    "                gradient_norm.append(total_norm)\n",
    "                print(f\"Epoch: {epoch:4}   Gradient: {total_norm}\")\n",
    "                \n",
    "                # Switch to evaluation mode\n",
    "                model.eval()\n",
    "        \n",
    "                print(forward_and_decode(inputs, targets))\n",
    "\n",
    "                sum_loss = 0.\n",
    "                for inputs, targets, target_lengths in loader_validation:\n",
    "                    sum_loss += forward_and_loss(inputs, targets, target_lengths).item()\n",
    "\n",
    "                # Average loss\n",
    "                sum_loss = sum_loss / len(loader_validation)\n",
    "                sum_loss_validation.append((epoch, sum_loss))\n",
    "                sum_loss_str += f\"   Validation: {sum_loss:.5f}\"\n",
    "\n",
    "                print(forward_and_decode(inputs, targets))\n",
    "\n",
    "                print(sum_loss_str)\n",
    "\n",
    "                if sum_loss < best_loss:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), f\"./model.{dtstamp}.{epoch}.ph\")\n",
    "                    best_loss = sum_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 1         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    4218 MB |    9037 MB |   11601 GB |   11597 GB |\n",
      "|       from large pool |     373 MB |    5192 MB |   11495 GB |   11495 GB |\n",
      "|       from small pool |    3844 MB |    3846 MB |     106 GB |     102 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    4218 MB |    9037 MB |   11601 GB |   11597 GB |\n",
      "|       from large pool |     373 MB |    5192 MB |   11495 GB |   11495 GB |\n",
      "|       from small pool |    3844 MB |    3846 MB |     106 GB |     102 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   14828 MB |   15262 MB |   23084 MB |    8256 MB |\n",
      "|       from large pool |   10938 MB |   12440 MB |   19192 MB |    8254 MB |\n",
      "|       from small pool |    3890 MB |    3890 MB |    3892 MB |       2 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  708080 KB |    1632 MB |    9127 GB |    9126 GB |\n",
      "|       from large pool |  663833 KB |    1501 MB |    8994 GB |    8994 GB |\n",
      "|       from small pool |   44247 KB |     141 MB |     132 GB |     132 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |   62523    |   62554    |     857 K  |     795 K  |\n",
      "|       from large pool |      28    |      51    |     307 K  |     307 K  |\n",
      "|       from small pool |   62495    |   62510    |     550 K  |     487 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |   62523    |   62554    |     857 K  |     795 K  |\n",
      "|       from large pool |      28    |      51    |     307 K  |     307 K  |\n",
      "|       from small pool |   62495    |   62510    |     550 K  |     487 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |    1971    |    1971    |    2002    |      31    |\n",
      "|       from large pool |      26    |      47    |      56    |      30    |\n",
      "|       from small pool |    1945    |    1945    |    1946    |       1    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |     894    |    2669    |  375023    |  374129    |\n",
      "|       from large pool |      12    |      28    |  141055    |  141043    |\n",
      "|       from small pool |     882    |    2656    |  233968    |  233086    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(*zip(*sum_loss_training), label=\"training\")\n",
    "plt.plot(*zip(*sum_loss_validation), label=\"validation\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_loss_training = [(a, math.log(b)) for (a,b) in sum_loss_training]\n",
    "sum_loss_validation = [(a, math.log(b)) for (a,b) in sum_loss_validation]\n",
    "\n",
    "plt.plot(*zip(*sum_loss_training), label=\"training\")\n",
    "plt.plot(*zip(*sum_loss_validation), label=\"validation\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         39849560 function calls (38985914 primitive calls) in 1562.462 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 2706 to 20 due to restriction <20>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       18    0.001    0.000 1562.460   86.803 base_events.py:1686(_run_once)\n",
      "      198    0.000    0.000 1558.254    7.870 events.py:86(_run)\n",
      "      198    0.000    0.000 1558.254    7.870 {method 'run' of 'Context' objects}\n",
      "      134    0.000    0.000 1558.253   11.629 ioloop.py:735(_run_callback)\n",
      "    76/14    0.001    0.000 1558.251  111.304 gen.py:716(run)\n",
      "   126/41    0.000    0.000 1558.250   38.006 {method 'send' of 'generator' objects}\n",
      "       12    0.000    0.000 1558.248  129.854 ioloop.py:690(<lambda>)\n",
      "       12    0.000    0.000 1558.248  129.854 gen.py:784(inner)\n",
      "    97/32    0.002    0.000 1558.245   48.695 gen.py:184(wrapper)\n",
      "       84    0.000    0.000 1558.242   18.550 kernelbase.py:347(process_one)\n",
      "       47    0.001    0.000 1558.240   33.154 kernelbase.py:225(dispatch_shell)\n",
      " 42281/83    0.056    0.000 1558.211   18.774 {built-in method builtins.next}\n",
      "    69/38    0.000    0.000 1558.184   41.005 gen.py:700(__init__)\n",
      "       41    0.001    0.000 1558.177   38.004 kernelbase.py:512(execute_request)\n",
      "       28    0.000    0.000 1558.172   55.649 kernelbase.py:363(dispatch_queue)\n",
      "       20    0.001    0.000 1558.127   77.906 ipkernel.py:262(do_execute)\n",
      "       20    0.000    0.000 1558.075   77.904 zmqshell.py:534(run_cell)\n",
      "       20    0.000    0.000 1558.075   77.904 interactiveshell.py:2831(run_cell)\n",
      "       20    0.000    0.000 1558.074   77.904 interactiveshell.py:2865(_run_cell)\n",
      "       20    0.000    0.000 1558.029   77.901 async_helpers.py:58(_pseudo_sync_runner)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), f\"./model.{dtstamp}.{epoch}.ph\")\n",
    "\n",
    "# Print performance\n",
    "pr.disable()\n",
    "s = StringIO()\n",
    "ps = pstats.Stats(pr, stream=s).strip_dirs().sort_stats(\"cumtime\").print_stats(20)\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9655172413793104, 1.0, 0.9491525423728814, 1.1071428571428572, 0.9333333333333333, 0.9714285714285714, 1.0, 1.0714285714285714, 0.9777777777777777, 1.0, 0.9803921568627451, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9649122807017544, 1.0, 0.9777777777777777, 1.0, 1.0238095238095237, 0.9375, 0.9795918367346939, 1.0, 0.9772727272727273, 0.9814814814814815, 0.9767441860465116, 1.1666666666666667, 1.0, 1.0344827586206897, 1.0, 0.9767441860465116, 0.9736842105263158, 0.9555555555555556, 1.0, 0.9722222222222222, 0.9714285714285714, 0.9361702127659575, 1.0, 1.0, 1.0, 1.025, 1.2, 0.8983050847457628, 1.0, 0.98, 0.9473684210526315, 0.9827586206896551, 1.0, 0.9795918367346939, 1.0, 1.0, 1.0, 1.0, 0.9636363636363636, 1.0232558139534884, 1.0, 0.9736842105263158, 0.984375, 0.9836065573770492, 0.9649122807017544, 0.9574468085106383, 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99415872261424"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://martin-thoma.com/word-error-rate-calculation/\n",
    "\n",
    "def wer(r, h):\n",
    "    \"\"\"\n",
    "    Calculation of WER with Levenshtein distance.\n",
    "\n",
    "    Works only for iterables up to 254 elements (uint8).\n",
    "    O(nm) time ans space complexity.\n",
    "    \"\"\"\n",
    "    # initialisation\n",
    "    import numpy\n",
    "    d = numpy.zeros((len(r)+1)*(len(h)+1), dtype=numpy.uint8)\n",
    "    d = d.reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    # computation\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitution = d[i-1][j-1] + 1\n",
    "                insertion    = d[i][j-1] + 1\n",
    "                deletion     = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "\n",
    "    return d[len(r)][len(h)]/len(r)\n",
    "\n",
    "\n",
    "def forward_decode_wer(inputs, targets):\n",
    "    output = model(inputs)\n",
    "    # output = output.transpose(0, 1)\n",
    "    output = greedy_decoder(output)\n",
    "\n",
    "    output = decode(output.tolist())\n",
    "    target = decode(targets.tolist())\n",
    "    \n",
    "    output = [o.replace(char_null, \"\").replace(char_pad, \" \").strip().split(\" \") for o in output]\n",
    "    target = [o.replace(char_null, \"\").replace(char_pad, \" \").strip().split(\" \") for o in target]\n",
    "    \n",
    "    wers = [wer(a, b) for a, b in zip(output, target)]\n",
    "\n",
    "    # print(wers)\n",
    "\n",
    "    return sum(wers) / len(wers)\n",
    "\n",
    "\n",
    "forward_decode_wer(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
