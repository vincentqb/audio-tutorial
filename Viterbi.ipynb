{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[with pytorch](https://gist.github.com/PetrochukM/afaa3613a99a8e7213d2efdd02ae4762)\n",
    "\n",
    "[notebook](https://github.com/napsternxg/pytorch-practice/blob/master/Viterbi%20decoding%20and%20CRF.ipynb)\n",
    "\n",
    "[with different rings](https://www.audiolabs-erlangen.de/resources/MIR/FMP/C5/C5S3_Viterbi.html)\n",
    "\n",
    "[python only?](https://stackoverflow.com/questions/9729968/python-implementation-of-viterbi-algorithm)\n",
    "\n",
    "[numpy](http://www.adeveloperdiary.com/data-science/machine-learning/implement-viterbi-algorithm-in-hidden-markov-model-using-python-and-r/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5c69f4b1f0>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "np.random.seed(2017)\n",
    "\n",
    "torch.manual_seed(2017)\n",
    "\n",
    "# from scipy.misc import logsumexp # Use it for reference checking implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emissions:\n",
      "[[ 9.  6.]\n",
      " [13. 10.]\n",
      " [ 8. 18.]\n",
      " [ 3. 15.]]\n",
      "Transitions:\n",
      "[[7. 8.]\n",
      " [0. 8.]]\n"
     ]
    }
   ],
   "source": [
    "seq_length, num_states = 4, 2\n",
    "emissions = np.random.randint(20, size=(seq_length, num_states))*1.\n",
    "transitions = np.random.randint(10, size=(num_states, num_states))*1.\n",
    "\n",
    "print(\"Emissions:\", emissions, sep=\"\\n\")\n",
    "print(\"Transitions:\", transitions, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (2, 2))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emissions.shape, transitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78.0, [0, 0, 1, 1])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def viterbi_decoding_numpy(emissions, transitions):\n",
    "    # Use help from: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/crf/python/ops/crf.py\n",
    "    scores = np.zeros_like(emissions)\n",
    "    back_pointers = np.zeros_like(emissions, dtype=\"int\")\n",
    "    scores = emissions[0]\n",
    "\n",
    "    # Generate most likely scores and paths for each step in sequence\n",
    "    for i in range(1, emissions.shape[0]):\n",
    "        score_with_transition = np.expand_dims(scores, 1) + transitions\n",
    "        scores = emissions[i] + score_with_transition.max(axis=0)\n",
    "        back_pointers[i] = np.argmax(score_with_transition, 0)\n",
    "    \n",
    "\n",
    "    # Generate the most likely path\n",
    "    viterbi = [np.argmax(scores)]\n",
    "    for bp in reversed(back_pointers[1:]):\n",
    "        viterbi.append(bp[viterbi[-1]])\n",
    "    viterbi.reverse()\n",
    "    viterbi_score = np.max(scores)\n",
    "\n",
    "    return viterbi_score, viterbi\n",
    "\n",
    "\n",
    "viterbi_decoding_numpy(emissions, transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78.0, [0, 0, 1, 1])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def zeros_like(m):\n",
    "    return zeros(len(m), len(m[0]))\n",
    "\n",
    "\n",
    "def zeros(d1, d2):\n",
    "    return list(list(0 for _ in range(d2)) for _ in range(d1))\n",
    "\n",
    "\n",
    "def apply_transpose(f, m):\n",
    "    return list(map(f, zip(*m)))\n",
    "\n",
    "\n",
    "def argmax(l):\n",
    "    return max(range(len(l)), key=lambda i: l[i])\n",
    "\n",
    "\n",
    "def add1d2d(m1, m2):\n",
    "    return [[v2 + v1 for v2 in m2_row] for m2_row, v1 in zip(m2, m1)]\n",
    "\n",
    "\n",
    "def add1d1d(v1, v2):\n",
    "    return [e + s for e, s in zip(v1, v2)]\n",
    "\n",
    "\n",
    "def viterbi_decoding_list(emissions, transitions):\n",
    "    scores = zeros_like(emissions)\n",
    "    back_pointers = zeros_like(emissions)\n",
    "    scores = emissions[0]\n",
    "\n",
    "    # Generate most likely scores and paths for each step in sequence\n",
    "    for i in range(1, len(emissions)):\n",
    "        score_with_transition = add1d2d(scores, transitions)\n",
    "        max_score_with_transition = apply_transpose(max, score_with_transition)\n",
    "        scores = add1d1d(emissions[i], max_score_with_transition)\n",
    "        back_pointers[i] = apply_transpose(argmax, score_with_transition)\n",
    "\n",
    "    # Generate the most likely path\n",
    "    viterbi = [argmax(scores)]\n",
    "    for bp in reversed(back_pointers[1:]):\n",
    "        viterbi.append(bp[viterbi[-1]])\n",
    "    viterbi.reverse()\n",
    "    viterbi_score = max(scores)\n",
    "\n",
    "    return viterbi_score, viterbi\n",
    "\n",
    "\n",
    "emissions_list = emissions.tolist()\n",
    "transitions_list = transitions.tolist()\n",
    "\n",
    "viterbi_decoding_list(emissions_list, transitions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 µs ± 143 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "36 µs ± 138 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit viterbi_decoding_numpy(emissions, transitions)\n",
    "%timeit viterbi_decoding_list(emissions_list, transitions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"hello\", \"world\", \"how\", \"are\", \"you\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 4, 11, 11, 14],\n",
       " [22, 14, 17, 11, 3],\n",
       " [7, 14, 22],\n",
       " [0, 17, 4],\n",
       " [24, 14, 20],\n",
       " [4, 4, 4, 4, 4]]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"hello\", \"world\", \"how\", \"are\", \"you\", \"eeeee\"]\n",
    "lm = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "tokens = [[lm.find(w) for w in word] for word in words]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def build_transitions(data_loader, n=2):\n",
    "\n",
    "    # Count n-grams\n",
    "    count = Counter()\n",
    "    for label in data_loader:\n",
    "        count += Counter(a for a in zip(*(label[i:] for i in range(n))))\n",
    "            \n",
    "    # Write as matrix                                                                                                                                                              \n",
    "    transitions = zeros(len(lm), len(lm))    \n",
    "    for (k1, k2), v in count.items():\n",
    "        transitions[k1][k2] = v\n",
    "\n",
    "    return transitions\n",
    "\n",
    "\n",
    "transitions = build_transitions(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 µs ± 338 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit build_transitions(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
